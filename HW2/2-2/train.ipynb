{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.840B.300d'\n",
    "config = {\n",
    "    'max_size': 48,\n",
    "    'min_freq': 0,\n",
    "    'batch_size': 32,\n",
    "    'pretrained_file': pretrained_file\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['sorry,', 'i', 'spent', 'it', 'on', 'myself!', 'harvey', \"nichols'\", 'hilarious', 'christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '0.18333333333333313'} {'Headline': ['three', 'police', 'officers', 'accused', 'of', 'stealing', '??', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "max_len = 0\n",
    "a = AttractiveData.train_data\n",
    "for i in range(len(a)):\n",
    "    if len(a[i].Headline) >= max_len:\n",
    "        max_len = len(a[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([12699, 300])\n"
     ]
    }
   ],
   "source": [
    "config['timestr'] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['save_name'] = 'CNN_LSTM'\n",
    "config['input_dim'] = len(AttractiveData.TEXT.vocab)\n",
    "config['embedding_dim'] = 300\n",
    "config['category_dim'] = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "config['category_embedding_dim'] = 16\n",
    "config['hidden_dim'] = 128\n",
    "config['output_dim'] = 1\n",
    "config['log_steps'] = 10\n",
    "config['epochs'] = 50\n",
    "config['lr'] = {\n",
    "    'encoder': 3e-5,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-5\n",
    "}\n",
    "config['num_layers'] = 2\n",
    "config['kernel_size'] = 3\n",
    "config['dropout'] = 0.1\n",
    "\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(config, AttractiveData.device, AttractiveData.trainloader, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(AttractiveNet(\n",
       "   (embedding): AttractiveEmbedding(\n",
       "     (token): TokenEmbedding(12699, 300, padding_idx=1)\n",
       "     (position): PositionalEmbedding()\n",
       "   )\n",
       "   (cnn1): Sequential(\n",
       "     (0): Conv1d(300, 256, kernel_size=(3,), stride=(1,))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (cnn2): Sequential(\n",
       "     (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (encoder): LSTM(128, 128, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "   (linear_output): Linear(in_features=512, out_features=1, bias=True)\n",
       " ),\n",
       " 4798757,\n",
       " 989057)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model, AttractiveTrainer.config['total_params'], AttractiveTrainer.config['total_learned_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch:   2%|▏         | 1/50 [00:00<00:25,  1.96it/s]\n",
      "EP_train | avg_loss: 0.5320876301266253 |\n",
      "Epoch:   4%|▍         | 2/50 [00:01<00:24,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5313345054164529 |\n",
      "Epoch:   6%|▌         | 3/50 [00:01<00:24,  1.91it/s]\n",
      "EP_train | avg_loss: 0.5326740257441998 |\n",
      "Epoch:   8%|▊         | 4/50 [00:02<00:23,  1.92it/s]\n",
      "EP_train | avg_loss: 0.5317059168592095 |\n",
      "Epoch:  10%|█         | 5/50 [00:02<00:23,  1.93it/s]\n",
      "EP_train | avg_loss: 0.5316830016672611 |\n",
      "Epoch:  12%|█▏        | 6/50 [00:03<00:22,  1.92it/s]\n",
      "EP_train | avg_loss: 0.5318275070749223 |\n",
      "Epoch:  14%|█▍        | 7/50 [00:03<00:22,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5328773471992463 |\n",
      "Epoch:  16%|█▌        | 8/50 [00:04<00:21,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5318045462481678 |\n",
      "Epoch:  18%|█▊        | 9/50 [00:04<00:21,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5309870732016861 |\n",
      "Epoch:  20%|██        | 10/50 [00:05<00:20,  1.92it/s]\n",
      "EP_train | avg_loss: 0.5324461525306106 |\n",
      "Epoch:  22%|██▏       | 11/50 [00:05<00:20,  1.93it/s]\n",
      "EP_train | avg_loss: 0.531581973657012 |\n",
      "Epoch:  24%|██▍       | 12/50 [00:06<00:19,  1.91it/s]\n",
      "EP_train | avg_loss: 0.5319209289737046 |\n",
      "Epoch:  26%|██▌       | 13/50 [00:06<00:19,  1.92it/s]\n",
      "EP_train | avg_loss: 0.5322228791192174 |\n",
      "Epoch:  28%|██▊       | 14/50 [00:07<00:18,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5310673951171339 |\n",
      "Epoch:  30%|███       | 15/50 [00:07<00:18,  1.94it/s]\n",
      "EP_train | avg_loss: 0.53159308899194 |\n",
      "Epoch:  32%|███▏      | 16/50 [00:08<00:17,  1.96it/s]\n",
      "EP_train | avg_loss: 0.5315202074125409 |\n",
      "Epoch:  34%|███▍      | 17/50 [00:08<00:17,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5316501455381513 |\n",
      "Epoch:  36%|███▌      | 18/50 [00:09<00:16,  1.93it/s]\n",
      "EP_train | avg_loss: 0.5318839247338474 |\n",
      "Epoch:  38%|███▊      | 19/50 [00:09<00:15,  1.96it/s]\n",
      "EP_train | avg_loss: 0.5329199228435755 |\n",
      "Epoch:  40%|████      | 20/50 [00:10<00:15,  1.97it/s]\n",
      "EP_train | avg_loss: 0.5321739003993571 |\n",
      "Epoch:  42%|████▏     | 21/50 [00:10<00:14,  1.99it/s]\n",
      "EP_train | avg_loss: 0.5316567630507052 |\n",
      "Epoch:  44%|████▍     | 22/50 [00:11<00:14,  1.99it/s]\n",
      "EP_train | avg_loss: 0.5314921331591904 |\n",
      "Epoch:  46%|████▌     | 23/50 [00:11<00:13,  1.99it/s]\n",
      "EP_train | avg_loss: 0.531494920141995 |\n",
      "Epoch:  48%|████▊     | 24/50 [00:12<00:13,  1.96it/s]\n",
      "EP_train | avg_loss: 0.5327004930004478 |\n",
      "Epoch:  50%|█████     | 25/50 [00:12<00:13,  1.92it/s]\n",
      "EP_train | avg_loss: 0.5322964314837009 |\n",
      "Epoch:  52%|█████▏    | 26/50 [00:13<00:12,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5318559347651899 |\n",
      "Epoch:  54%|█████▍    | 27/50 [00:13<00:11,  1.96it/s]\n",
      "EP_train | avg_loss: 0.531355588696897 |\n",
      "Epoch:  56%|█████▌    | 28/50 [00:14<00:11,  1.96it/s]\n",
      "EP_train | avg_loss: 0.5314408014528453 |\n",
      "Epoch:  58%|█████▊    | 29/50 [00:14<00:10,  1.96it/s]\n",
      "EP_train | avg_loss: 0.5321927205659449 |\n",
      "Epoch:  60%|██████    | 30/50 [00:15<00:10,  1.98it/s]\n",
      "EP_train | avg_loss: 0.5314979399554431 |\n",
      "Epoch:  62%|██████▏   | 31/50 [00:15<00:09,  2.00it/s]\n",
      "EP_train | avg_loss: 0.533832039218396 |\n",
      "Epoch:  64%|██████▍   | 32/50 [00:16<00:09,  1.99it/s]\n",
      "EP_train | avg_loss: 0.533009194303304 |\n",
      "Epoch:  66%|██████▌   | 33/50 [00:16<00:08,  2.00it/s]\n",
      "EP_train | avg_loss: 0.5322038196027279 |\n",
      "Epoch:  68%|██████▊   | 34/50 [00:17<00:08,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5321546043269336 |\n",
      "Epoch:  70%|███████   | 35/50 [00:17<00:07,  1.93it/s]\n",
      "EP_train | avg_loss: 0.5311157666146755 |\n",
      "Epoch:  72%|███████▏  | 36/50 [00:18<00:07,  1.93it/s]\n",
      "EP_train | avg_loss: 0.5321237777825445 |\n",
      "Epoch:  74%|███████▍  | 37/50 [00:18<00:06,  1.96it/s]\n",
      "EP_train | avg_loss: 0.53288992960006 |\n",
      "Epoch:  76%|███████▌  | 38/50 [00:19<00:06,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5315665733069181 |\n",
      "Epoch:  78%|███████▊  | 39/50 [00:19<00:05,  1.99it/s]\n",
      "EP_train | avg_loss: 0.5315951651427895 |\n",
      "Epoch:  80%|████████  | 40/50 [00:20<00:05,  1.97it/s]\n",
      "EP_train | avg_loss: 0.5316842822358012 |\n",
      "Epoch:  82%|████████▏ | 41/50 [00:20<00:04,  2.01it/s]\n",
      "EP_train | avg_loss: 0.5326422210782766 |\n",
      "Epoch:  84%|████████▍ | 42/50 [00:21<00:03,  2.01it/s]\n",
      "EP_train | avg_loss: 0.5331210652366281 |\n",
      "Epoch:  86%|████████▌ | 43/50 [00:22<00:03,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5319054829888046 |\n",
      "Epoch:  88%|████████▊ | 44/50 [00:22<00:03,  1.93it/s]\n",
      "EP_train | avg_loss: 0.531471214722842 |\n",
      "Epoch:  90%|█████████ | 45/50 [00:23<00:02,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5325147919356823 |\n",
      "Epoch:  92%|█████████▏| 46/50 [00:23<00:02,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5324016585946083 |\n",
      "Epoch:  94%|█████████▍| 47/50 [00:24<00:01,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5315539408475161 |\n",
      "Epoch:  96%|█████████▌| 48/50 [00:24<00:01,  1.98it/s]\n",
      "EP_train | avg_loss: 0.5325450394302607 |\n",
      "Epoch:  98%|█████████▊| 49/50 [00:25<00:00,  1.94it/s]\n",
      "EP_train | avg_loss: 0.5323784765787423 |\n",
      "Epoch: 100%|██████████| 50/50 [00:25<00:00,  1.95it/s]\n",
      "EP_train | avg_loss: 0.5331239830702543 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5601443355119825"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# a = AttractiveTrainer.train_predict\n",
    "# AttractiveData.LABEL.vocab.itos[int(a[0])], AttractiveTrainer.train_true[0]\n",
    "# correct = 0\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "# for i in range(len(a)):\n",
    "#     pred = AttractiveData.LABEL.vocab.itos[int(a[i])]\n",
    "#     pred_list.append(float(pred))\n",
    "#     true = AttractiveData.LABEL.vocab.itos[int(AttractiveTrainer.train_true[i])]\n",
    "#     true_list.append(float(true))\n",
    "# mean_squared_error(true_list, pred_list)\n",
    "# # true_list"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(12699, 300, padding_idx=1)\n",
       "    (position): PositionalEmbedding()\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv1d(300, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (encoder): LSTM(128, 128, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "  (linear_output): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from attractivenet import AttractiveNet\n",
    "PATH = './model/CNN_LSTM_20201031-222546_0.5331.50'\n",
    "# load_model = TransformerModel(config).to(AttractiveData.device)\n",
    "load_model = AttractiveNet(config).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    if len(sentence) < config['max_size']:\n",
    "        sentence += ['0'] * (config['max_size'] - len(sentence))\n",
    "    else:\n",
    "        sentence = sentence[:config['max_size']]\n",
    "\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "predict_list = []\n",
    "with torch.no_grad():\n",
    "    for i, sentence in enumerate(AttractiveData.test_data):\n",
    "        # print(i)\n",
    "        # print(sentence.Headline)\n",
    "        prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "        predict_list.append(prediction.item() + 2.8)\n",
    "        # predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv(config['save_name'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "# test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "# for each_test in test_category:\n",
    "#     if each_test not in train_category:\n",
    "#         print(each_test)\n",
    "# print()\n",
    "# for each_train in train_category:\n",
    "#     if each_train not in test_category:\n",
    "#         print(each_train)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10.4140600453376, 0.00680579473116143, 0.0013295569592471203)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "train_list = []\n",
    "for i, sentence in enumerate(AttractiveData.train_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    # train_list.append(prediction.item() + 3.15)\n",
    "    train_list.append(prediction.item())\n",
    "mean_squared_error(pd.read_csv('data/train.csv').sort_values(['ID']).Label.to_list(), train_list), statistics.mean(train_list), statistics.stdev(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0004084967320261136, 0.7295015193216009)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "a = AttractiveData.df_train['Label'].to_list()\n",
    "statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.806901204586029, 0.0014380726065986002)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.09400285430663444, 2.7156126782757597, 0.29355123275379763)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "baseline_list = pd.read_csv('baseline.csv').sort_values(['ID']).Label.to_list()\n",
    "mean_squared_error(baseline_list, predict_list), statistics.mean(baseline_list), statistics.stdev(baseline_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.8167915543795683, 0.14611407210842048)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# LSTM my best\n",
    "# statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.1347375515605904, 2.8379913731293533, 0.1903582104725371)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "a = pd.read_csv('LSTM_base.csv').Label.to_list()\n",
    "mean_squared_error(baseline_list, a), statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}