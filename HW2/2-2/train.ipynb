{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.42B.300d'\n",
    "max_size = 64\n",
    "min_freq = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.3333333333333335'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = next(iter(AttractiveData.testloader))\n",
    "# for i in range(len(a)):\n",
    "#     print(a.Headline[i], a.Category[i])\n",
    "#     1/0"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1410, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = './model/AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "\n",
    "category_dim = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "category_output_dim = 16\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "num_layers = 3\n",
    "nhead = 4\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, AttractiveData.testloader, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers, nhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1410, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(22, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  47%|| 15/32 [00:00<00:00, 140.83it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  94%|| 30/32 [00:00<00:00, 141.39it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 141.19it/s]\n",
      "EP_train | avg_loss: 0.5630883509293199 |\n",
      "Epoch 94\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  44%|| 14/32 [00:00<00:00, 137.17it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "EP: train | lr: 0.001:  91%|| 29/32 [00:00<00:00, 139.23it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 140.84it/s]\n",
      "EP_train | avg_loss: 0.5663917809724808 |\n",
      "Epoch 95\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  47%|| 15/32 [00:00<00:00, 144.63it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  94%|| 30/32 [00:00<00:00, 145.18it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 144.97it/s]\n",
      "EP_train | avg_loss: 0.5641064094379544 |\n",
      "Epoch 96\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  47%|| 15/32 [00:00<00:00, 141.21it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  91%|| 29/32 [00:00<00:00, 139.71it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 139.45it/s]\n",
      "EP_train | avg_loss: 0.566819928586483 |\n",
      "Epoch 97\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  47%|| 15/32 [00:00<00:00, 140.46it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  94%|| 30/32 [00:00<00:00, 142.53it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 143.24it/s]\n",
      "EP_train | avg_loss: 0.5632114363834262 |\n",
      "Epoch 98\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  47%|| 15/32 [00:00<00:00, 146.05it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  94%|| 30/32 [00:00<00:00, 146.81it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 147.79it/s]\n",
      "EP_train | avg_loss: 0.5617909906432033 |\n",
      "Epoch 99\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  47%|| 15/32 [00:00<00:00, 143.93it/s]torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001:  94%|| 30/32 [00:00<00:00, 144.84it/s]torch.Size([56, 300]) torch.Size([56, 16])\n",
      "torch.Size([64, 300]) torch.Size([64, 16])\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 145.44it/s]\n",
      "EP_train | avg_loss: 0.5599180292338133 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1410, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(22, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from transformermodel import TransformerModel\n",
    "PATH = './model/AttractiveNet_20201028-235812_0.563.100'\n",
    "load_model = TransformerModel(nhead, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, dropout, num_layers).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    tokens = AttractiveData.tokenizer(sentence)\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in tokens]\n",
    "    indexed_category = AttractiveData.CATEGORIES_LABEL.vocab[category]\n",
    "    print(indexed_sentence, indexed_category)\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1).unsqueeze(1)\n",
    "    tensor_category = tensor_category.unsqueeze(1)\n",
    "    print(tensor_sentence.shape, tensor_category.shape)\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    # prediction = 0\n",
    "\n",
    "    # print(prediction.shape)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 141, 0, 0, 190, 36, 215, 0, 6, 1143, 4, 132, 76, 405, 155, 109, 0, 42, 95, 140, 8, 41, 215, 205, 8, 429, 0] 4\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2eb4e9b2bdf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cancer left Eric With half his face missing and unable to eat or drink. now surgeons have made him a new face using a 3d printer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"travel\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_attractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c4fadaf4dd87>\u001b[0m in \u001b[0;36mpredict_attractive\u001b[0;34m(sentence, category)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexed_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttractiveData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATEGORIES_LABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtensor_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtensor_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "a = \"Cancer left Eric With half his face missing and unable to eat or drink. now surgeons have made him a new face using a 3d printer\"\n",
    "c = \"travel\"\n",
    "prediction = predict_attractive(a, c)\n",
    "prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_headline = AttractiveData.df_test['ID'].to_list()\n",
    "# predict_list = []\n",
    "# for i in range(len(test_headline)):\n",
    "#     predict_list.append(predict_attractive(AttractiveData.df_test.Headline[i], AttractiveData.df_test.Category[i]).item())\n",
    "# AttractiveData.df_test['Label'] = predict_list\n",
    "# AttractiveData.df_test\n",
    "# # AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'Text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c5e00d7c3c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             self.batches = batch(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    252\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/attractivedata.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucketIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucketIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "next(iter(AttractiveData.testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_headline = AttractiveData.df_test['Headline'].to_list()\n",
    "predict_list = []\n",
    "for i in range(len(test_headline)):\n",
    "    predict_list.append(predict_attractive(test_headline[i]).item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}