{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.42B.300d'\n",
    "config = {\n",
    "    'max_size': 64,\n",
    "    'min_freq': 5,\n",
    "    'batch_size': 64\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.333333333333333'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in range(i):\n",
    "    if len(AttractiveData.test_data[i].Headline) >= max_len:\n",
    "        max_len = len(AttractiveData.test_data[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1519, 300])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 10\n",
    "\n",
    "config['timestr'] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['save_name'] = 'LSTM'\n",
    "config['input_dim'] = len(AttractiveData.TEXT.vocab)\n",
    "config['embedding_dim'] = 300\n",
    "config['category_dim'] = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "config['category_embedding_dim'] = 16\n",
    "config['hidden_dim'] = 256\n",
    "config['output_dim'] = 1\n",
    "config['log_steps'] = 10\n",
    "config['epochs'] = 200\n",
    "config['lr'] = {\n",
    "    'encoder': 1e-4,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-4\n",
    "}\n",
    "config['num_layers'] = 3\n",
    "config['nhead'] = 4\n",
    "config['dropout'] = 0.1\n",
    "\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(config, AttractiveData.device, AttractiveData.trainloader, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1519, 300, padding_idx=1)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "  (encoder): LSTM(300, 256, num_layers=3, dropout=0.1)\n",
       "  (linear): Linear(in_features=272, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ch 80\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.64it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7981985304504633 |\n",
      "Epoch 81\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.27it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7907169256359339 |\n",
      "Epoch 82\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7857140302658081 |\n",
      "Epoch 83\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.89it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7745080664753914 |\n",
      "Epoch 84\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7726117614656687 |\n",
      "Epoch 85\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.59it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7638187948614359 |\n",
      "Epoch 86\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7583766188472509 |\n",
      "Epoch 87\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.55it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7523589730262756 |\n",
      "Epoch 88\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.29it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7419199980795383 |\n",
      "Epoch 89\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.78it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7394784558564425 |\n",
      "Epoch 90\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.40it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7360488846898079 |\n",
      "Epoch 91\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7322705294936895 |\n",
      "Epoch 92\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.21it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7278094757348299 |\n",
      "Epoch 93\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.93it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7253395821899176 |\n",
      "Epoch 94\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 178.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7179724108427763 |\n",
      "Epoch 95\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 196.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7154133953154087 |\n",
      "Epoch 96\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 185.55it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7164998445659876 |\n",
      "Epoch 97\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.00it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.711078142747283 |\n",
      "Epoch 98\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 189.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7039855886250734 |\n",
      "Epoch 99\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.93it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7039327062666416 |\n",
      "Epoch 100\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 190.77it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7021653261035681 |\n",
      "Epoch 101\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6983209419995546 |\n",
      "Epoch 102\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.66it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6959810685366392 |\n",
      "Epoch 103\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 175.16it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6943533103913069 |\n",
      "Epoch 104\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 188.96it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6919494494795799 |\n",
      "Epoch 105\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.68719189055264 |\n",
      "Epoch 106\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.37it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6872043991461396 |\n",
      "Epoch 107\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6866786759346724 |\n",
      "Epoch 108\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.42it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6839018249884248 |\n",
      "Epoch 109\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.65it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6788777653127909 |\n",
      "Epoch 110\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.92it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.680825537070632 |\n",
      "Epoch 111\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6764426399022341 |\n",
      "Epoch 112\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.66it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6775482799857855 |\n",
      "Epoch 113\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.58it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.676141144707799 |\n",
      "Epoch 114\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.94it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6721557434648275 |\n",
      "Epoch 115\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 197.53it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6714138966053724 |\n",
      "Epoch 116\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.12it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6680586766451597 |\n",
      "Epoch 117\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 186.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6662708912044764 |\n",
      "Epoch 118\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 184.63it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6682800184935331 |\n",
      "Epoch 119\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.03it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6649206969887018 |\n",
      "Epoch 120\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 190.91it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6623525656759739 |\n",
      "Epoch 121\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 189.94it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6664381194859743 |\n",
      "Epoch 122\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.48it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6589682111516595 |\n",
      "Epoch 123\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 186.78it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6603513043373823 |\n",
      "Epoch 124\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.34it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.658935084939003 |\n",
      "Epoch 125\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 180.50it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6584248505532742 |\n",
      "Epoch 126\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 196.90it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6565827652812004 |\n",
      "Epoch 127\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 189.48it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6559459008276463 |\n",
      "Epoch 128\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 196.30it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6535924961790442 |\n",
      "Epoch 129\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 189.28it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6532710138708353 |\n",
      "Epoch 130\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 183.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6510790195316076 |\n",
      "Epoch 131\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 184.58it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6512941848486662 |\n",
      "Epoch 132\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 189.28it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6482250224798918 |\n",
      "Epoch 133\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.51it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6483879946172237 |\n",
      "Epoch 134\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 183.73it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6490839812904596 |\n",
      "Epoch 135\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.646278427913785 |\n",
      "Epoch 136\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.29it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6463053151965141 |\n",
      "Epoch 137\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.97it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6461083870381117 |\n",
      "Epoch 138\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6455501262098551 |\n",
      "Epoch 139\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.43it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6431119814515114 |\n",
      "Epoch 140\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.47it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6440610233694315 |\n",
      "Epoch 141\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6395853441208601 |\n",
      "Epoch 142\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.34it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6398246763274074 |\n",
      "Epoch 143\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.00it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6385609190911055 |\n",
      "Epoch 144\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6388798160478473 |\n",
      "Epoch 145\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 197.71it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6377777494490147 |\n",
      "Epoch 146\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6349299438297749 |\n",
      "Epoch 147\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.76it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.635794572532177 |\n",
      "Epoch 148\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.00it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.634303143247962 |\n",
      "Epoch 149\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 190.58it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6345297526568174 |\n",
      "Epoch 150\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.32it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6320126475766301 |\n",
      "Epoch 151\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6321352478116751 |\n",
      "Epoch 152\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.18it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6306718336418271 |\n",
      "Epoch 153\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.63407245837152 |\n",
      "Epoch 154\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.30it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6285193301737309 |\n",
      "Epoch 155\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.68it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6291998410597444 |\n",
      "Epoch 156\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.628625774756074 |\n",
      "Epoch 157\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6288490165024996 |\n",
      "Epoch 158\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.73it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6258931308984756 |\n",
      "Epoch 159\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.67it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6268697008490562 |\n",
      "Epoch 160\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.01it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6270483396947384 |\n",
      "Epoch 161\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.97it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6247425200417638 |\n",
      "Epoch 162\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 188.83it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.623311011120677 |\n",
      "Epoch 163\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6248643975704908 |\n",
      "Epoch 164\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 177.84it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6235952824354172 |\n",
      "Epoch 165\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.81it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6241089040413499 |\n",
      "Epoch 166\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.15it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6237785648554564 |\n",
      "Epoch 167\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 186.41it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6228573573753238 |\n",
      "Epoch 168\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.84it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6196845108643174 |\n",
      "Epoch 169\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 187.80it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6182100456207991 |\n",
      "Epoch 170\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 179.81it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6182321989908814 |\n",
      "Epoch 171\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.49it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6191047029569745 |\n",
      "Epoch 172\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.78it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6187510322779417 |\n",
      "Epoch 173\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.77it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6174801690503955 |\n",
      "Epoch 174\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6184132248163223 |\n",
      "Epoch 175\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.616806979291141 |\n",
      "Epoch 176\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 189.30it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6167059540748596 |\n",
      "Epoch 177\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.70it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.615926755592227 |\n",
      "Epoch 178\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.51it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6171682868152857 |\n",
      "Epoch 179\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.45it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6129268584772944 |\n",
      "Epoch 180\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.48it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6162276100367308 |\n",
      "Epoch 181\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.23it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6134515292942524 |\n",
      "Epoch 182\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 188.66it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6125940699130297 |\n",
      "Epoch 183\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 183.80it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6146641550585628 |\n",
      "Epoch 184\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.54it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6123312134295702 |\n",
      "Epoch 185\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.74it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6145658260211349 |\n",
      "Epoch 186\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.22it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.610826887190342 |\n",
      "Epoch 187\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 193.90it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6090337205678225 |\n",
      "Epoch 188\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6099867662414908 |\n",
      "Epoch 189\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.76it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6077758921310306 |\n",
      "Epoch 190\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 190.69it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6076935743913054 |\n",
      "Epoch 191\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 188.75it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6096587600186467 |\n",
      "Epoch 192\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 194.80it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6090571116656065 |\n",
      "Epoch 193\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 192.30it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6087593771517277 |\n",
      "Epoch 194\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 188.68it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6082570273429155 |\n",
      "Epoch 195\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 191.47it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6066150479018688 |\n",
      "Epoch 196\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.605469947680831 |\n",
      "Epoch 197\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 190.97it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6051722206175327 |\n",
      "Epoch 198\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.02it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6067893980070949 |\n",
      "Epoch 199\n",
      "EP: train | lr: {'encoder': 0.0001, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 195.69it/s]\n",
      "EP_train | avg_loss: 0.6041887728497386 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5601443355119825"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# a = AttractiveTrainer.train_predict\n",
    "# AttractiveData.LABEL.vocab.itos[int(a[0])], AttractiveTrainer.train_true[0]\n",
    "# correct = 0\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "# for i in range(len(a)):\n",
    "#     pred = AttractiveData.LABEL.vocab.itos[int(a[i])]\n",
    "#     pred_list.append(float(pred))\n",
    "#     true = AttractiveData.LABEL.vocab.itos[int(AttractiveTrainer.train_true[i])]\n",
    "#     true_list.append(float(true))\n",
    "# mean_squared_error(true_list, pred_list)\n",
    "# # true_list"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1519, 300, padding_idx=1)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "  (encoder): LSTM(300, 256, num_layers=3, dropout=0.1)\n",
       "  (linear): Linear(in_features=272, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from transformermodel import TransformerModel\n",
    "from attractivenet import AttractiveNet\n",
    "PATH = './model/LSTM_20201030-162411_0.604.200'\n",
    "# load_model = TransformerModel(config).to(AttractiveData.device)\n",
    "load_model = AttractiveNet(config).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "    tensor_category = tensor_category\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train mean = 3.2, test mean = 2.8\n",
    "predict_list = []\n",
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    # predict_list.append(prediction.item() - 3.2 + 2.8)\n",
    "    predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv(config['save_name'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ngolf\nbeauty\n"
     ]
    }
   ],
   "source": [
    "train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "for each_test in test_category:\n",
    "    if each_test not in train_category:\n",
    "        print(each_test)\n",
    "print()\n",
    "for each_train in train_category:\n",
    "    if each_train not in test_category:\n",
    "        print(each_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['travel',\n",
       "  'health',\n",
       "  'femail',\n",
       "  'sport',\n",
       "  'gardening',\n",
       "  'sciencetech',\n",
       "  'news',\n",
       "  'food',\n",
       "  'football',\n",
       "  'travelnews',\n",
       "  'cricket',\n",
       "  'golf',\n",
       "  'books',\n",
       "  'rugbyunion',\n",
       "  'home',\n",
       "  'boxing',\n",
       "  'tennis',\n",
       "  'concussion',\n",
       "  'othersports',\n",
       "  'beauty',\n",
       "  'formulaone',\n",
       "  'racing'],\n",
       " ['health',\n",
       "  'femail',\n",
       "  'sciencetech',\n",
       "  'travel',\n",
       "  'news',\n",
       "  'football',\n",
       "  'food',\n",
       "  'living',\n",
       "  'books',\n",
       "  'boxing',\n",
       "  'rugbyunion',\n",
       "  'othersports',\n",
       "  'formulaone',\n",
       "  'cricket',\n",
       "  'us',\n",
       "  'tennis',\n",
       "  'sport',\n",
       "  'middleeast',\n",
       "  'racing'])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_category, test_category"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}