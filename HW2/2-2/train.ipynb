{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "# def tokenizer(corpus):\n",
    "#     return [str(token) for token in nlp(corpus)]\n",
    "# a = '\"River walk that led me to my secret family: after being adopted as a child, Katharine Norbury reveals the emotional journey to reconnect with her biological mother\"'.replace('\"', '')\n",
    "# tokenizer(a)"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_file = './pretrained_embedding/glove.840B.300d.txt'\n",
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "max_size = 128\n",
    "min_freq = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Label': '3.3333333333333335'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Label': ''}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([582, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = './model/AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 30\n",
    "lr = 1e-3\n",
    "num_layers = 2\n",
    "nhead = 4\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, AttractiveData.testloader, input_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers, nhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(582, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP:0 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 45.20it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 116.74it/s]\n",
      "EP:1 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.87it/s]\n",
      "EP_train | avg_loss: 9.886443376541138 |\n",
      "EP:1 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.61it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.23it/s]\n",
      "EP:2 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.63it/s]\n",
      "EP_train | avg_loss: 9.814950540661812 |\n",
      "EP:2 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.22it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.67it/s]\n",
      "EP:3 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.54it/s]\n",
      "EP_train | avg_loss: 9.696655988693237 |\n",
      "EP:3 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.75it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 115.81it/s]\n",
      "EP:4 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.03it/s]\n",
      "EP_train | avg_loss: 9.788543984293938 |\n",
      "EP:4 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.62it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 119.90it/s]\n",
      "EP:5 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.25it/s]\n",
      "EP_train | avg_loss: 9.726820155978203 |\n",
      "EP:5 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.76it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 117.54it/s]\n",
      "EP:6 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 48.57it/s]\n",
      "EP_train | avg_loss: 9.733242243528366 |\n",
      "EP:6 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.33it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 107.66it/s]\n",
      "EP:7 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.65it/s]\n",
      "EP_train | avg_loss: 9.709816008806229 |\n",
      "EP:7 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 46.38it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.02it/s]\n",
      "EP:8 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 48.14it/s]\n",
      "EP_train | avg_loss: 9.695358857512474 |\n",
      "EP:8 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.78it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 119.14it/s]\n",
      "EP:9 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.76it/s]\n",
      "EP_train | avg_loss: 9.675334438681602 |\n",
      "EP:9 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 46.94it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.68it/s]\n",
      "EP:10 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 45.08it/s]\n",
      "EP_train | avg_loss: 9.699098870158195 |\n",
      "EP:10 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.28it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.61it/s]\n",
      "EP:11 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.35it/s]\n",
      "EP_train | avg_loss: 9.721308559179306 |\n",
      "EP:11 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.35it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 117.95it/s]\n",
      "EP:12 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 48.04it/s]\n",
      "EP_train | avg_loss: 9.686047583818436 |\n",
      "EP:12 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.96it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 115.15it/s]\n",
      "EP:13 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.15it/s]\n",
      "EP_train | avg_loss: 9.7644654661417 |\n",
      "EP:13 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.57it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 119.03it/s]\n",
      "EP:14 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 45.75it/s]\n",
      "EP_train | avg_loss: 9.777210161089897 |\n",
      "EP:14 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 46.51it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 116.98it/s]\n",
      "EP:15 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.09it/s]\n",
      "EP_train | avg_loss: 9.657488539814949 |\n",
      "EP:15 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.78it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.12it/s]\n",
      "EP:16 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.77it/s]\n",
      "EP_train | avg_loss: 9.682247534394264 |\n",
      "EP:16 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.58it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 116.81it/s]\n",
      "EP:17 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.67it/s]\n",
      "EP_train | avg_loss: 9.7181296646595 |\n",
      "EP:17 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.71it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 119.12it/s]\n",
      "EP:18 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.92it/s]\n",
      "EP_train | avg_loss: 9.663052260875702 |\n",
      "EP:18 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 46.44it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.87it/s]\n",
      "EP:19 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.62it/s]\n",
      "EP_train | avg_loss: 9.816915348172188 |\n",
      "EP:19 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.50it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 117.68it/s]\n",
      "EP:20 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.14it/s]\n",
      "EP_train | avg_loss: 10.28827415406704 |\n",
      "EP:20 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.27it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 117.46it/s]\n",
      "EP:21 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 45.37it/s]\n",
      "EP_train | avg_loss: 9.68363593518734 |\n",
      "EP:21 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.11it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 120.66it/s]\n",
      "EP:22 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.79it/s]\n",
      "EP_train | avg_loss: 9.71732060611248 |\n",
      "EP:22 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 46.86it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 117.67it/s]\n",
      "EP:23 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.40it/s]\n",
      "EP_train | avg_loss: 9.768977627158165 |\n",
      "EP:23 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.71it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.85it/s]\n",
      "EP:24 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.57it/s]\n",
      "EP_train | avg_loss: 9.695572271943092 |\n",
      "EP:24 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.88it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 117.22it/s]\n",
      "EP:25 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 45.48it/s]\n",
      "EP_train | avg_loss: 9.966567531228065 |\n",
      "EP:25 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.06it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 116.97it/s]\n",
      "EP:26 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.49it/s]\n",
      "EP_train | avg_loss: 9.670525595545769 |\n",
      "EP:26 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.02it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 115.12it/s]\n",
      "EP:27 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 46.20it/s]\n",
      "EP_train | avg_loss: 9.754434183239937 |\n",
      "EP:27 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.27it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 115.94it/s]\n",
      "EP:28 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 47.96it/s]\n",
      "EP_train | avg_loss: 9.73388235270977 |\n",
      "EP:28 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.24it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 112.58it/s]\n",
      "EP:29 | lr: 0.001:  16%|| 5/32 [00:00<00:00, 45.66it/s]\n",
      "EP_train | avg_loss: 9.831398636102676 |\n",
      "EP:29 | lr: 0.001: 100%|| 32/32 [00:00<00:00, 47.57it/s]\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 118.85it/s]\n",
      "EP_train | avg_loss: 9.655261054635048 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP:0 | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  0,   0, 288,  ..., 526,   0,   0],\n",
      "        [849,  15, 458,  ...,   0,   8, 300],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([ 0.,  2., 13.,  7.,  4.,  3.,  2.,  1.,  1.,  2.,  5., 11.,  0.,  1.,\n",
      "         6.,  0.,  1.,  6.,  4.,  3.,  1.,  0.,  3.,  3.,  2.,  6.,  0.,  2.,\n",
      "         9.,  4., 12.,  7.,  6.,  1.,  1.,  2.,  3.,  1.,  3.,  5., 11.,  5.,\n",
      "         2.,  9., 11.,  0.,  1.,  6.,  0.,  0.,  8.,  1.,  5.,  0.,  9.,  4.,\n",
      "        13.,  3.,  2.,  2.,  1.,  3.,  0.,  6.], device='cuda:0')\n",
      "tensor([[[ 6.0121e-01],\n",
      "         [ 3.5993e-01],\n",
      "         [ 2.6935e-01],\n",
      "         ...,\n",
      "         [ 9.3061e-01],\n",
      "         [ 6.7218e-01],\n",
      "         [ 5.9746e-01]],\n",
      "\n",
      "        [[ 5.3440e-01],\n",
      "         [ 5.7120e-01],\n",
      "         [ 9.3283e-01],\n",
      "         ...,\n",
      "         [ 2.4973e-01],\n",
      "         [ 4.3619e-01],\n",
      "         [ 9.2209e-01]],\n",
      "\n",
      "        [[ 9.8335e-01],\n",
      "         [ 3.1896e-01],\n",
      "         [ 4.8618e-01],\n",
      "         ...,\n",
      "         [ 6.4320e-01],\n",
      "         [ 8.7757e-01],\n",
      "         [ 4.3513e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.3695e-01],\n",
      "         [ 6.3075e-01],\n",
      "         [-3.0097e-02],\n",
      "         ...,\n",
      "         [ 5.4032e-01],\n",
      "         [ 3.4146e-02],\n",
      "         [ 3.6431e-01]],\n",
      "\n",
      "        [[ 9.0569e-02],\n",
      "         [ 3.6251e-01],\n",
      "         [ 1.3408e-01],\n",
      "         ...,\n",
      "         [ 1.3202e-04],\n",
      "         [ 5.2705e-01],\n",
      "         [ 3.9068e-01]],\n",
      "\n",
      "        [[ 4.9548e-01],\n",
      "         [ 4.6397e-01],\n",
      "         [ 5.6939e-01],\n",
      "         ...,\n",
      "         [ 6.6638e-01],\n",
      "         [ 4.2747e-01],\n",
      "         [ 7.1454e-01]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([128, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 1])\n",
      "25.996700286865234\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bb6f4c62359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# self.scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattractive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# NLLLoss of predicting masked token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP:0 | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [ 48, 241,   0,  ...,   0, 805,   0],\n",
      "        [211,   3,   0,  ...,   0,  13, 303],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([ 4.,  1.,  2.,  2.,  0., 13.,  3.,  9.,  1.,  1.,  3.,  3.,  2.,  1.,\n",
      "         2.,  2.,  0.,  8.,  1.,  9.,  0.,  1.,  0.,  3.,  6., 10.,  2.,  7.,\n",
      "         4.,  1.,  2.,  2.,  6.,  6.,  2., 14.,  2.,  3.,  7.,  0.,  4.,  3.,\n",
      "         1., 13.,  0.,  0.,  1.,  1.,  1.,  0.,  4.,  2.,  5.,  1.,  3.,  5.,\n",
      "         0.,  2.,  0.,  8.,  1.,  0.,  9.,  1.], device='cuda:0')\n",
      "tensor([[-0.2539],\n",
      "        [-0.8596],\n",
      "        [-1.1908],\n",
      "        [-1.5457],\n",
      "        [-0.2728],\n",
      "        [-0.9879],\n",
      "        [-0.8742],\n",
      "        [-1.1552],\n",
      "        [-1.1962],\n",
      "        [-1.4770],\n",
      "        [-0.5963],\n",
      "        [-1.6508],\n",
      "        [-0.5904],\n",
      "        [-1.2092],\n",
      "        [-1.4268],\n",
      "        [-0.2909],\n",
      "        [-0.8780],\n",
      "        [-0.6749],\n",
      "        [-1.1115],\n",
      "        [-0.8630],\n",
      "        [-0.9790],\n",
      "        [-0.7880],\n",
      "        [-0.8269],\n",
      "        [-1.3190],\n",
      "        [-1.4739],\n",
      "        [-1.3425],\n",
      "        [-1.2339],\n",
      "        [-1.1160],\n",
      "        [-1.2770],\n",
      "        [-1.3377],\n",
      "        [-1.7300],\n",
      "        [-1.4053],\n",
      "        [-1.4985],\n",
      "        [-1.3642],\n",
      "        [-1.3358],\n",
      "        [-0.9606],\n",
      "        [-1.2042],\n",
      "        [-1.6164],\n",
      "        [-1.3799],\n",
      "        [-1.1898],\n",
      "        [-1.4967],\n",
      "        [-1.4721],\n",
      "        [-1.7613],\n",
      "        [-1.1037],\n",
      "        [-1.0040],\n",
      "        [-1.5401],\n",
      "        [-1.0843],\n",
      "        [-0.8682],\n",
      "        [-1.2682],\n",
      "        [-1.1550],\n",
      "        [-1.3988],\n",
      "        [-1.3398],\n",
      "        [-1.3936],\n",
      "        [-1.7836],\n",
      "        [-1.6804],\n",
      "        [-1.3008],\n",
      "        [-1.5489],\n",
      "        [-1.1335],\n",
      "        [-1.3884],\n",
      "        [-1.5549],\n",
      "        [-1.2522],\n",
      "        [-1.0548],\n",
      "        [-1.2672],\n",
      "        [-1.3845],\n",
      "        [-1.4811],\n",
      "        [-1.4342],\n",
      "        [-1.3536],\n",
      "        [-1.1534],\n",
      "        [-1.1998],\n",
      "        [-1.2637],\n",
      "        [-1.5077],\n",
      "        [-1.4890],\n",
      "        [-1.3994],\n",
      "        [-1.1649],\n",
      "        [-1.4032],\n",
      "        [-1.4273],\n",
      "        [-1.5072],\n",
      "        [-1.2913],\n",
      "        [-1.4187],\n",
      "        [-1.5821],\n",
      "        [-1.1610],\n",
      "        [-1.1004],\n",
      "        [-1.0985],\n",
      "        [-0.8344],\n",
      "        [-1.6426],\n",
      "        [-1.0117],\n",
      "        [-0.9649],\n",
      "        [-1.3412],\n",
      "        [-1.1632],\n",
      "        [-1.0748],\n",
      "        [-1.5117],\n",
      "        [-1.1857],\n",
      "        [-1.3199],\n",
      "        [-1.0420],\n",
      "        [-1.3646],\n",
      "        [-1.2566],\n",
      "        [-1.3299],\n",
      "        [-1.3563],\n",
      "        [-1.5357],\n",
      "        [-1.5247],\n",
      "        [-1.0464],\n",
      "        [-1.2225],\n",
      "        [-1.3271],\n",
      "        [-1.2447],\n",
      "        [-1.9028],\n",
      "        [-1.4855],\n",
      "        [-1.5180],\n",
      "        [-1.4581],\n",
      "        [-1.5808],\n",
      "        [-1.3883],\n",
      "        [-1.2648],\n",
      "        [-1.0551],\n",
      "        [-1.5557],\n",
      "        [-1.3459],\n",
      "        [-0.9999],\n",
      "        [-1.5748],\n",
      "        [-1.5305],\n",
      "        [-1.3661],\n",
      "        [-1.4075],\n",
      "        [-1.0807],\n",
      "        [-1.1934],\n",
      "        [-1.7515],\n",
      "        [-1.5570],\n",
      "        [-1.5616],\n",
      "        [-1.4749],\n",
      "        [-1.3812],\n",
      "        [-0.9541],\n",
      "        [-1.5316]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([128, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 1])\n",
      "32.67628479003906\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bb6f4c62359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# self.scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattractive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# NLLLoss of predicting masked token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence):\n",
    "    tokens = AttractiveData.tokenizer(sentence)\n",
    "    indexed = [AttractiveData.TEXT.vocab.stoi[t] for t in tokens]\n",
    "    print(indexed)\n",
    "    tensor = torch.LongTensor(indexed).to(AttractiveData.device)\n",
    "\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    print(tensor.shape)\n",
    "    prediction = AttractiveTrainer.model(tensor)\n",
    "\n",
    "    print(prediction.shape)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 7, 97, 12, 0, 12, 20, 139, 22, 0, 1085, 21, 84, 0, 16, 0]\ntorch.Size([16, 1])\ntorch.Size([1, 1])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2.6075]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "a = \"Body of man, 34, is found at recycling plant after being delivered with rubbish\"\n",
    "prediction = predict_attractive(a)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP: test | lr: 0.01:   0%|| 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'Text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2143512279e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_loader, str_code)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHeadline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mattractive_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             self.batches = batch(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    252\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/attractivedata.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         self.trainloader, self.testloader = data.BucketIterator.splits(\n\u001b[0;32m---> 36\u001b[0;31m             (self.train_data, self.test_data), sort_key=lambda x: len(x.Text), batch_size=batch_size, device=self.device)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# self.padding_train = self.padding(self.df_train.Headline.to_list())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "pred, true = AttractiveTrainer.evaluate(AttractiveTrainer.test_loader, 'test')"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}