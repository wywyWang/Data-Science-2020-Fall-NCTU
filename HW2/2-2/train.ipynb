{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.6B.200d'\n",
    "config = {\n",
    "    'max_size': 64,\n",
    "    'min_freq': 5,\n",
    "    'batch_size': 64,\n",
    "    'pretrained_file': pretrained_file\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.333333333333333'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in range(i):\n",
    "    if len(AttractiveData.test_data[i].Headline) >= max_len:\n",
    "        max_len = len(AttractiveData.test_data[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1518, 200])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 10\n",
    "\n",
    "config['timestr'] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['save_name'] = 'LSTM'\n",
    "config['input_dim'] = len(AttractiveData.TEXT.vocab)\n",
    "config['embedding_dim'] = 300\n",
    "config['category_dim'] = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "config['category_embedding_dim'] = 16\n",
    "config['hidden_dim'] = 64\n",
    "config['output_dim'] = 1\n",
    "config['log_steps'] = 10\n",
    "config['epochs'] = 100\n",
    "config['lr'] = {\n",
    "    'encoder': 1e-4,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-4\n",
    "}\n",
    "config['num_layers'] = 2\n",
    "config['nhead'] = 4\n",
    "config['dropout'] = 0.1\n",
    "\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(config, AttractiveData.device, AttractiveData.trainloader, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(AttractiveNet(\n",
       "   (embedding): AttractiveEmbedding(\n",
       "     (token): TokenEmbedding(1518, 200, padding_idx=1)\n",
       "     (position): PositionalEmbedding()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "   (encoder): LSTM(200, 64, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "   (linear_output): Linear(in_features=144, out_features=1, bias=True)\n",
       " ),\n",
       " 539553,\n",
       " 235953)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model, AttractiveTrainer.config['total_params'], AttractiveTrainer.config['total_learned_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch:   1%|          | 1/100 [00:00<00:48,  2.02it/s]\n",
      "EP_train | avg_loss: 6.642789602279663 |\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:47,  2.06it/s]\n",
      "EP_train | avg_loss: 1.399132400751114 |\n",
      "Epoch:   3%|▎         | 3/100 [00:01<00:46,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5566003285348415 |\n",
      "Epoch:   4%|▍         | 4/100 [00:01<00:45,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5459084836766124 |\n",
      "Epoch:   5%|▌         | 5/100 [00:02<00:44,  2.11it/s]\n",
      "EP_train | avg_loss: 0.54395058657974 |\n",
      "Epoch:   6%|▌         | 6/100 [00:02<00:44,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5424360195174813 |\n",
      "Epoch:   7%|▋         | 7/100 [00:03<00:45,  2.06it/s]\n",
      "EP_train | avg_loss: 0.5435706898570061 |\n",
      "Epoch:   8%|▊         | 8/100 [00:03<00:45,  2.03it/s]\n",
      "EP_train | avg_loss: 0.5438382206484675 |\n",
      "Epoch:   9%|▉         | 9/100 [00:04<00:44,  2.06it/s]\n",
      "EP_train | avg_loss: 0.5446662735193968 |\n",
      "Epoch:  10%|█         | 10/100 [00:04<00:43,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5431200014427304 |\n",
      "Epoch:  11%|█         | 11/100 [00:05<00:42,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5438010562211275 |\n",
      "Epoch:  12%|█▏        | 12/100 [00:05<00:42,  2.08it/s]\n",
      "EP_train | avg_loss: 0.5438466006889939 |\n",
      "Epoch:  13%|█▎        | 13/100 [00:06<00:41,  2.08it/s]\n",
      "EP_train | avg_loss: 0.5447595315054059 |\n",
      "Epoch:  14%|█▍        | 14/100 [00:06<00:41,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5433308286592364 |\n",
      "Epoch:  15%|█▌        | 15/100 [00:07<00:40,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5436243955045938 |\n",
      "Epoch:  16%|█▌        | 16/100 [00:07<00:39,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5424243453890085 |\n",
      "Epoch:  17%|█▋        | 17/100 [00:08<00:39,  2.13it/s]\n",
      "EP_train | avg_loss: 0.543069732375443 |\n",
      "Epoch:  18%|█▊        | 18/100 [00:08<00:38,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5449391836300492 |\n",
      "Epoch:  19%|█▉        | 19/100 [00:09<00:37,  2.15it/s]\n",
      "EP_train | avg_loss: 0.5433562751859426 |\n",
      "Epoch:  20%|██        | 20/100 [00:09<00:37,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5436229333281517 |\n",
      "Epoch:  21%|██        | 21/100 [00:09<00:37,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5421380242332816 |\n",
      "Epoch:  22%|██▏       | 22/100 [00:10<00:36,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5418004803359509 |\n",
      "Epoch:  23%|██▎       | 23/100 [00:10<00:36,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5454363888129592 |\n",
      "Epoch:  24%|██▍       | 24/100 [00:11<00:35,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5413226867094636 |\n",
      "Epoch:  25%|██▌       | 25/100 [00:11<00:35,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5419983370229602 |\n",
      "Epoch:  26%|██▌       | 26/100 [00:12<00:34,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5444520153105259 |\n",
      "Epoch:  27%|██▋       | 27/100 [00:12<00:34,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5433022575452924 |\n",
      "Epoch:  28%|██▊       | 28/100 [00:13<00:34,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5443835528567433 |\n",
      "Epoch:  29%|██▉       | 29/100 [00:13<00:33,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5407394822686911 |\n",
      "Epoch:  30%|███       | 30/100 [00:14<00:32,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5426437230780721 |\n",
      "Epoch:  31%|███       | 31/100 [00:14<00:32,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5446412367746234 |\n",
      "Epoch:  32%|███▏      | 32/100 [00:15<00:31,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5411059325560927 |\n",
      "Epoch:  33%|███▎      | 33/100 [00:15<00:31,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5436605094000697 |\n",
      "Epoch:  34%|███▍      | 34/100 [00:16<00:30,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5405627433210611 |\n",
      "Epoch:  35%|███▌      | 35/100 [00:16<00:31,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5408683996647596 |\n",
      "Epoch:  36%|███▌      | 36/100 [00:17<00:30,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5486806146800518 |\n",
      "Epoch:  37%|███▋      | 37/100 [00:17<00:30,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5410966482013464 |\n",
      "Epoch:  38%|███▊      | 38/100 [00:18<00:29,  2.08it/s]\n",
      "EP_train | avg_loss: 0.5412642490118742 |\n",
      "Epoch:  39%|███▉      | 39/100 [00:18<00:29,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5451041087508202 |\n",
      "Epoch:  40%|████      | 40/100 [00:18<00:28,  2.12it/s]\n",
      "EP_train | avg_loss: 0.541168499737978 |\n",
      "Epoch:  41%|████      | 41/100 [00:19<00:27,  2.12it/s]\n",
      "EP_train | avg_loss: 0.54198407381773 |\n",
      "Epoch:  42%|████▏     | 42/100 [00:19<00:27,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5436973823234439 |\n",
      "Epoch:  43%|████▎     | 43/100 [00:20<00:26,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5441225674003363 |\n",
      "Epoch:  44%|████▍     | 44/100 [00:20<00:26,  2.12it/s]\n",
      "EP_train | avg_loss: 0.540254051797092 |\n",
      "Epoch:  45%|████▌     | 45/100 [00:21<00:26,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5419818544760346 |\n",
      "Epoch:  46%|████▌     | 46/100 [00:21<00:25,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5440187379717827 |\n",
      "Epoch:  47%|████▋     | 47/100 [00:22<00:25,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5410754783079028 |\n",
      "Epoch:  48%|████▊     | 48/100 [00:22<00:25,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5412839185446501 |\n",
      "Epoch:  49%|████▉     | 49/100 [00:23<00:24,  2.04it/s]\n",
      "EP_train | avg_loss: 0.5430437363684177 |\n",
      "Epoch:  50%|█████     | 50/100 [00:23<00:24,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5443008430302143 |\n",
      "Epoch:  51%|█████     | 51/100 [00:24<00:23,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5441727433353662 |\n",
      "Epoch:  52%|█████▏    | 52/100 [00:24<00:22,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5445619402453303 |\n",
      "Epoch:  53%|█████▎    | 53/100 [00:25<00:22,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5396809251978993 |\n",
      "Epoch:  54%|█████▍    | 54/100 [00:25<00:21,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5400285050272942 |\n",
      "Epoch:  55%|█████▌    | 55/100 [00:26<00:21,  2.08it/s]\n",
      "EP_train | avg_loss: 0.5387875633314252 |\n",
      "Epoch:  56%|█████▌    | 56/100 [00:26<00:21,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5401436137035489 |\n",
      "Epoch:  57%|█████▋    | 57/100 [00:27<00:20,  2.06it/s]\n",
      "EP_train | avg_loss: 0.5402877945452929 |\n",
      "Epoch:  58%|█████▊    | 58/100 [00:27<00:20,  2.06it/s]\n",
      "EP_train | avg_loss: 0.539694445207715 |\n",
      "Epoch:  59%|█████▉    | 59/100 [00:28<00:19,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5395493442192674 |\n",
      "Epoch:  60%|██████    | 60/100 [00:28<00:19,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5391425145789981 |\n",
      "Epoch:  61%|██████    | 61/100 [00:29<00:18,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5426215687766671 |\n",
      "Epoch:  62%|██████▏   | 62/100 [00:29<00:17,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5391063038259745 |\n",
      "Epoch:  63%|██████▎   | 63/100 [00:29<00:17,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5391823258250952 |\n",
      "Epoch:  64%|██████▍   | 64/100 [00:30<00:16,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5392183568328619 |\n",
      "Epoch:  65%|██████▌   | 65/100 [00:30<00:16,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5387696688994765 |\n",
      "Epoch:  66%|██████▌   | 66/100 [00:31<00:15,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5393294300884008 |\n",
      "Epoch:  67%|██████▋   | 67/100 [00:31<00:15,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5379509991034865 |\n",
      "Epoch:  68%|██████▊   | 68/100 [00:32<00:14,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5385332610458136 |\n",
      "Epoch:  69%|██████▉   | 69/100 [00:32<00:14,  2.15it/s]\n",
      "EP_train | avg_loss: 0.5401647882536054 |\n",
      "Epoch:  70%|███████   | 70/100 [00:33<00:13,  2.15it/s]\n",
      "EP_train | avg_loss: 0.5405520796775818 |\n",
      "Epoch:  71%|███████   | 71/100 [00:33<00:13,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5395223796367645 |\n",
      "Epoch:  72%|███████▏  | 72/100 [00:34<00:13,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5390606243163347 |\n",
      "Epoch:  73%|███████▎  | 73/100 [00:34<00:12,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5393078802153468 |\n",
      "Epoch:  74%|███████▍  | 74/100 [00:35<00:12,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5380855677649379 |\n",
      "Epoch:  75%|███████▌  | 75/100 [00:35<00:12,  2.07it/s]\n",
      "EP_train | avg_loss: 0.5385006265714765 |\n",
      "Epoch:  76%|███████▌  | 76/100 [00:36<00:11,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5418628985062242 |\n",
      "Epoch:  77%|███████▋  | 77/100 [00:36<00:10,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5397185580804944 |\n",
      "Epoch:  78%|███████▊  | 78/100 [00:37<00:10,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5390009628608823 |\n",
      "Epoch:  79%|███████▉  | 79/100 [00:37<00:09,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5396609026938677 |\n",
      "Epoch:  80%|████████  | 80/100 [00:37<00:09,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5384570583701134 |\n",
      "Epoch:  81%|████████  | 81/100 [00:38<00:08,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5403144992887974 |\n",
      "Epoch:  82%|████████▏ | 82/100 [00:38<00:08,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5374335087835789 |\n",
      "Epoch:  83%|████████▎ | 83/100 [00:39<00:08,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5390588287264109 |\n",
      "Epoch:  84%|████████▍ | 84/100 [00:39<00:07,  2.13it/s]\n",
      "EP_train | avg_loss: 0.539313075132668 |\n",
      "Epoch:  85%|████████▌ | 85/100 [00:40<00:07,  2.13it/s]\n",
      "EP_train | avg_loss: 0.538918886333704 |\n",
      "Epoch:  86%|████████▌ | 86/100 [00:40<00:06,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5370860518887639 |\n",
      "Epoch:  87%|████████▋ | 87/100 [00:41<00:06,  2.09it/s]\n",
      "EP_train | avg_loss: 0.5381532777100801 |\n",
      "Epoch:  88%|████████▊ | 88/100 [00:41<00:05,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5374035136774182 |\n",
      "Epoch:  89%|████████▉ | 89/100 [00:42<00:05,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5397305646911263 |\n",
      "Epoch:  90%|█████████ | 90/100 [00:42<00:04,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5394592685624957 |\n",
      "Epoch:  91%|█████████ | 91/100 [00:43<00:04,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5373924933373928 |\n",
      "Epoch:  92%|█████████▏| 92/100 [00:43<00:03,  2.12it/s]\n",
      "EP_train | avg_loss: 0.5367924114689231 |\n",
      "Epoch:  93%|█████████▎| 93/100 [00:44<00:03,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5368244843557477 |\n",
      "Epoch:  94%|█████████▍| 94/100 [00:44<00:02,  2.14it/s]\n",
      "EP_train | avg_loss: 0.5370174990966916 |\n",
      "Epoch:  95%|█████████▌| 95/100 [00:45<00:02,  2.15it/s]\n",
      "EP_train | avg_loss: 0.536461578682065 |\n",
      "Epoch:  96%|█████████▌| 96/100 [00:45<00:01,  2.15it/s]\n",
      "EP_train | avg_loss: 0.5367451123893261 |\n",
      "Epoch:  97%|█████████▋| 97/100 [00:45<00:01,  2.16it/s]\n",
      "EP_train | avg_loss: 0.5365495579317212 |\n",
      "Epoch:  98%|█████████▊| 98/100 [00:46<00:00,  2.13it/s]\n",
      "EP_train | avg_loss: 0.5378719493746758 |\n",
      "Epoch:  99%|█████████▉| 99/100 [00:46<00:00,  2.10it/s]\n",
      "EP_train | avg_loss: 0.5378774851560593 |\n",
      "Epoch: 100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n",
      "EP_train | avg_loss: 0.5368820382282138 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5601443355119825"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# a = AttractiveTrainer.train_predict\n",
    "# AttractiveData.LABEL.vocab.itos[int(a[0])], AttractiveTrainer.train_true[0]\n",
    "# correct = 0\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "# for i in range(len(a)):\n",
    "#     pred = AttractiveData.LABEL.vocab.itos[int(a[i])]\n",
    "#     pred_list.append(float(pred))\n",
    "#     true = AttractiveData.LABEL.vocab.itos[int(AttractiveTrainer.train_true[i])]\n",
    "#     true_list.append(float(true))\n",
    "# mean_squared_error(true_list, pred_list)\n",
    "# # true_list"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AttractiveNet:\n\tsize mismatch for embedding.token.weight: copying a param with shape torch.Size([1518, 300]) from checkpoint, the shape in current model is torch.Size([1518, 200]).\n\tsize mismatch for embedding.position.pe: copying a param with shape torch.Size([1, 128, 300]) from checkpoint, the shape in current model is torch.Size([1, 128, 200]).\n\tsize mismatch for encoder.weight_ih_l0: copying a param with shape torch.Size([256, 300]) from checkpoint, the shape in current model is torch.Size([256, 200]).\n\tsize mismatch for encoder.weight_ih_l0_reverse: copying a param with shape torch.Size([256, 300]) from checkpoint, the shape in current model is torch.Size([256, 200]).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1fb064945eb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load_model = TransformerModel(config).to(AttractiveData.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mload_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttractiveNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AttractiveNet:\n\tsize mismatch for embedding.token.weight: copying a param with shape torch.Size([1518, 300]) from checkpoint, the shape in current model is torch.Size([1518, 200]).\n\tsize mismatch for embedding.position.pe: copying a param with shape torch.Size([1, 128, 300]) from checkpoint, the shape in current model is torch.Size([1, 128, 200]).\n\tsize mismatch for encoder.weight_ih_l0: copying a param with shape torch.Size([256, 300]) from checkpoint, the shape in current model is torch.Size([256, 200]).\n\tsize mismatch for encoder.weight_ih_l0_reverse: copying a param with shape torch.Size([256, 300]) from checkpoint, the shape in current model is torch.Size([256, 200])."
     ]
    }
   ],
   "source": [
    "from transformermodel import TransformerModel\n",
    "from attractivenet import AttractiveNet\n",
    "PATH = './model/LSTM_20201031-114350_0.5422.100'\n",
    "# load_model = TransformerModel(config).to(AttractiveData.device)\n",
    "load_model = AttractiveNet(config).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "    tensor_category = tensor_category\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train mean = 3.2, test mean = 2.8\n",
    "predict_list = []\n",
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    # predict_list.append(prediction.item() - 3.2 + 2.8)\n",
    "    predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv(config['save_name'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "# test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "# for each_test in test_category:\n",
    "#     if each_test not in train_category:\n",
    "#         print(each_test)\n",
    "# print()\n",
    "# for each_train in train_category:\n",
    "#     if each_train not in test_category:\n",
    "#         print(each_train)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3.150408496732026, 0.729501519321601)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "a = AttractiveData.df_train['Label'].to_list()\n",
    "statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.7234197466383945, 0.15732692202737075)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.030507257007487312"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "all_28 = [2.8] * len(predict_list)\n",
    "mean_squared_error(all_28, predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.8167915543795683, 0.14611407210842048)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# LSTM my best\n",
    "# statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}