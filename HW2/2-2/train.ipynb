{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.42B.300d'\n",
    "max_size = 64\n",
    "min_freq = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.3333333333333335'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'travel': 283,\n",
       "         'health': 289,\n",
       "         'femail': 291,\n",
       "         'sport': 11,\n",
       "         'gardening': 10,\n",
       "         'sciencetech': 292,\n",
       "         'news': 291,\n",
       "         'food': 208,\n",
       "         'football': 220,\n",
       "         'travelnews': 9,\n",
       "         'cricket': 7,\n",
       "         'golf': 5,\n",
       "         'books': 66,\n",
       "         'rugbyunion': 14,\n",
       "         'home': 7,\n",
       "         'boxing': 4,\n",
       "         'tennis': 13,\n",
       "         'concussion': 1,\n",
       "         'othersports': 12,\n",
       "         'beauty': 1,\n",
       "         'formulaone': 4,\n",
       "         'racing': 2})"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "AttractiveData.CATEGORIES_LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = next(iter(AttractiveData.testloader))\n",
    "# for i in range(len(a)):\n",
    "#     print(a.Headline[i], a.Category[i])\n",
    "#     1/0"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1410, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = './model/AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "\n",
    "category_dim = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "category_output_dim = 16\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "num_layers = 3\n",
    "nhead = 4\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers, nhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1410, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(22, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.93it/s]\n",
      "\n",
      "EP_train | avg_loss: 1.5890047065913677 |\n",
      "Epoch 1\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.98it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7881287876516581 |\n",
      "Epoch 2\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 157.19it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7345287501811981 |\n",
      "Epoch 3\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 150.67it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7286438476294279 |\n",
      "Epoch 4\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.28it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7130521778017282 |\n",
      "Epoch 5\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.76it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.7084342855960131 |\n",
      "Epoch 6\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 157.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6933034658432007 |\n",
      "Epoch 7\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6839309819042683 |\n",
      "Epoch 8\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.96it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6738497614860535 |\n",
      "Epoch 9\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6657202299684286 |\n",
      "Epoch 10\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.68it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6584968958050013 |\n",
      "Epoch 11\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.67it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6511358469724655 |\n",
      "Epoch 12\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.71it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6478283954784274 |\n",
      "Epoch 13\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6407519672065973 |\n",
      "Epoch 14\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.12it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6358957011252642 |\n",
      "Epoch 15\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.21it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6344446130096912 |\n",
      "Epoch 16\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6292172968387604 |\n",
      "Epoch 17\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.40it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6256153667345643 |\n",
      "Epoch 18\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.22it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6232383418828249 |\n",
      "Epoch 19\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.49it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.616903224028647 |\n",
      "Epoch 20\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.93it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6143856393173337 |\n",
      "Epoch 21\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.89it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6109593799337745 |\n",
      "Epoch 22\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.62it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6140577085316181 |\n",
      "Epoch 23\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.42it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6098985215649009 |\n",
      "Epoch 24\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.78it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6082959119230509 |\n",
      "Epoch 25\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6037955554202199 |\n",
      "Epoch 26\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.53it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5995797384530306 |\n",
      "Epoch 27\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.02it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6003030501306057 |\n",
      "Epoch 28\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.48it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5962760495021939 |\n",
      "Epoch 29\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.56it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5985973747447133 |\n",
      "Epoch 30\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.42it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5996819194406271 |\n",
      "Epoch 31\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.50it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.59151416644454 |\n",
      "Epoch 32\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 148.89it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5946566835045815 |\n",
      "Epoch 33\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.79it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5933588370680809 |\n",
      "Epoch 34\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5942248916253448 |\n",
      "Epoch 35\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.21it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5871557537466288 |\n",
      "Epoch 36\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.51it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5917263692244887 |\n",
      "Epoch 37\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.53it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5899935895577073 |\n",
      "Epoch 38\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.79it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5862813303247094 |\n",
      "Epoch 39\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.14it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5840569008141756 |\n",
      "Epoch 40\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.55it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5822129212319851 |\n",
      "Epoch 41\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 157.10it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5840065041556954 |\n",
      "Epoch 42\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.12it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5844328356906772 |\n",
      "Epoch 43\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5827782461419702 |\n",
      "Epoch 44\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.12it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5794035131111741 |\n",
      "Epoch 45\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.54it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5795238185673952 |\n",
      "Epoch 46\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5806157290935516 |\n",
      "Epoch 47\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.71it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5780916335061193 |\n",
      "Epoch 48\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.08it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.579667373560369 |\n",
      "Epoch 49\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.99it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5784469796344638 |\n",
      "Epoch 50\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.575804203748703 |\n",
      "Epoch 51\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 150.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5805395627394319 |\n",
      "Epoch 52\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.574924087151885 |\n",
      "Epoch 53\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.50it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5755592165514827 |\n",
      "Epoch 54\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 152.20it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5748876379802823 |\n",
      "Epoch 55\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.84it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5736820148304105 |\n",
      "Epoch 56\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.67it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5729996124282479 |\n",
      "Epoch 57\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.69it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5742361107841134 |\n",
      "Epoch 58\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.73it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5731853824108839 |\n",
      "Epoch 59\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 157.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5712822405621409 |\n",
      "Epoch 60\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5715372944250703 |\n",
      "Epoch 61\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.95it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5734975850209594 |\n",
      "Epoch 62\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5750765185803175 |\n",
      "Epoch 63\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 150.24it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5725442375987768 |\n",
      "Epoch 64\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.29it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5737742967903614 |\n",
      "Epoch 65\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 148.22it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5716355033218861 |\n",
      "Epoch 66\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.27it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5722296554595232 |\n",
      "Epoch 67\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.77it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.568875789642334 |\n",
      "Epoch 68\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 150.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.571216557174921 |\n",
      "Epoch 69\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.47it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5689054923132062 |\n",
      "Epoch 70\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 145.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5679218340665102 |\n",
      "Epoch 71\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 149.70it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5700087267905474 |\n",
      "Epoch 72\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.95it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5703942747786641 |\n",
      "Epoch 73\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.44it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5722731193527579 |\n",
      "Epoch 74\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.40it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5693073570728302 |\n",
      "Epoch 75\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.21it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5692860577255487 |\n",
      "Epoch 76\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5667047435417771 |\n",
      "Epoch 77\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 149.33it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5677945669740438 |\n",
      "Epoch 78\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.65it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5638853218406439 |\n",
      "Epoch 79\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.11it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5639121327549219 |\n",
      "Epoch 80\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5668031806126237 |\n",
      "Epoch 81\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.568884483538568 |\n",
      "Epoch 82\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.16it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.564817126840353 |\n",
      "Epoch 83\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 155.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5655806828290224 |\n",
      "Epoch 84\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.94it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5662783551961184 |\n",
      "Epoch 85\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5642018662765622 |\n",
      "Epoch 86\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5661923829466105 |\n",
      "Epoch 87\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 156.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5657715648412704 |\n",
      "Epoch 88\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.22it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5671111792325974 |\n",
      "Epoch 89\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5648209629580379 |\n",
      "Epoch 90\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 154.94it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.567456996999681 |\n",
      "Epoch 91\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 152.46it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5643124338239431 |\n",
      "Epoch 92\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 152.73it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5651213023811579 |\n",
      "Epoch 93\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 148.12it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5624186154454947 |\n",
      "Epoch 94\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5640039360150695 |\n",
      "Epoch 95\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 150.98it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5668642884120345 |\n",
      "Epoch 96\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 151.66it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5650641527026892 |\n",
      "Epoch 97\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 147.24it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5648106001317501 |\n",
      "Epoch 98\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 153.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5618660505861044 |\n",
      "Epoch 99\n",
      "EP: train | lr: 0.001: 100%|| 32/32 [00:00<00:00, 150.80it/s]\n",
      "EP_train | avg_loss: 0.5636152373626828 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1410, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(22, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from transformermodel import TransformerModel\n",
    "PATH = './model/AttractiveNet_20201029-114109_0.564.100'\n",
    "load_model = TransformerModel(nhead, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, dropout, num_layers).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    if category == 'living':\n",
    "        category = 'home'\n",
    "    if category == 'middleeast':\n",
    "        category = 'news'\n",
    "    if category == 'us':\n",
    "        category = 'news'\n",
    "    \n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "    tensor_category = tensor_category\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "predict_list = []\n",
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "living\nmiddleeast\nus\n"
     ]
    }
   ],
   "source": [
    "train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "for each_test in test_category:\n",
    "    if each_test not in train_category:\n",
    "        print(each_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['travel',\n",
       " 'health',\n",
       " 'femail',\n",
       " 'sport',\n",
       " 'gardening',\n",
       " 'sciencetech',\n",
       " 'news',\n",
       " 'food',\n",
       " 'football',\n",
       " 'travelnews',\n",
       " 'cricket',\n",
       " 'golf',\n",
       " 'books',\n",
       " 'rugbyunion',\n",
       " 'home',\n",
       " 'boxing',\n",
       " 'tennis',\n",
       " 'concussion',\n",
       " 'othersports',\n",
       " 'beauty',\n",
       " 'formulaone',\n",
       " 'racing']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "train_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_headline = AttractiveData.df_test['Headline'].to_list()\n",
    "predict_list = []\n",
    "for i in range(len(test_headline)):\n",
    "    predict_list.append(predict_attractive(test_headline[i]).item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}