{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "# def tokenizer(corpus):\n",
    "#     return [str(token) for token in nlp(corpus)]\n",
    "# a = '\"River walk that led me to my secret family: after being adopted as a child, Katharine Norbury reveals the emotional journey to reconnect with her biological mother\"'.replace('\"', '')\n",
    "# tokenizer(a)"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_file = 'glove.840B.300d'\n",
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "max_size = 64\n",
    "min_freq = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'harvey', 'nichols', \"'\", 'hilarious', 'christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.3333333333333335'} {'Headline': ['three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news', 'Label': ''}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor(4.6667, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f16f9db10fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHeadline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "a = next(iter(AttractiveData.trainloader))\n",
    "for i in range(len(a)):\n",
    "    print(a.Headline[i], a.Label[i])\n",
    "    1/0"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1432, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = './model/AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 100\n",
    "lr = 1e-5\n",
    "num_layers = 2\n",
    "nhead = 4\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, AttractiveData.testloader, input_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers, nhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1432, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "EP:6 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 76.94it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 177.39it/s]\n",
      "EP:7 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 75.00it/s]\n",
      "EP_train | avg_loss: 2.8246096819639206 |\n",
      "EP:7 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 75.40it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 158.32it/s]\n",
      "EP:8 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 73.95it/s]\n",
      "EP_train | avg_loss: 2.5004172921180725 |\n",
      "EP:8 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 74.40it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 170.88it/s]\n",
      "EP:9 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 77.13it/s]\n",
      "EP_train | avg_loss: 2.2228206992149353 |\n",
      "EP:9 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 76.67it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 168.92it/s]\n",
      "EP:10 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 76.14it/s]\n",
      "EP_train | avg_loss: 1.9791988208889961 |\n",
      "EP:10 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 76.07it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 174.91it/s]\n",
      "EP:11 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 72.52it/s]\n",
      "EP_train | avg_loss: 1.778807856142521 |\n",
      "EP:11 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 74.65it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 170.93it/s]\n",
      "EP:12 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 78.02it/s]\n",
      "EP_train | avg_loss: 1.604391798377037 |\n",
      "EP:12 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 77.44it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 168.91it/s]\n",
      "EP:13 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 70.95it/s]\n",
      "EP_train | avg_loss: 1.45463827252388 |\n",
      "EP:13 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 73.94it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 167.25it/s]\n",
      "EP:14 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 76.18it/s]\n",
      "EP_train | avg_loss: 1.3272452726960182 |\n",
      "EP:14 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 75.31it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 172.25it/s]\n",
      "EP:15 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 72.82it/s]\n",
      "EP_train | avg_loss: 1.2183500900864601 |\n",
      "EP:15 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 75.57it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 175.24it/s]\n",
      "EP:16 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 75.80it/s]\n",
      "EP_train | avg_loss: 1.1250871494412422 |\n",
      "EP:16 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 71.91it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 161.39it/s]\n",
      "EP:17 | lr: 1e-05:  50%|| 8/16 [00:00<00:00, 76.24it/s]\n",
      "EP_train | avg_loss: 1.0476180724799633 |\n",
      "EP:17 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 78.91it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 187.34it/s]\n",
      "EP:18 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 81.55it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.9778318628668785 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 198.12it/s]\n",
      "EP:19 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 86.50it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.923757653683424 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.56it/s]\n",
      "EP:20 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.47it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.8754757754504681 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 187.10it/s]\n",
      "EP:21 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.69it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.8335873335599899 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 188.38it/s]\n",
      "EP:22 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.68it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.7991167567670345 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 191.96it/s]\n",
      "EP:23 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 82.92it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.7717659138143063 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 194.19it/s]\n",
      "EP:24 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 86.00it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.7474159337580204 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 195.19it/s]\n",
      "EP:25 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 81.77it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.7270126529037952 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 195.86it/s]\n",
      "EP:26 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 86.34it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.7101846970617771 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.47it/s]\n",
      "EP:27 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.15it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6973537653684616 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.39it/s]\n",
      "EP:28 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.98it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6865663565695286 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 195.07it/s]\n",
      "EP:29 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.10it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6778145954012871 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 191.86it/s]\n",
      "EP:30 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.77it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6685763299465179 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 171.73it/s]\n",
      "EP:31 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.35it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6625044979155064 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 196.38it/s]\n",
      "EP:32 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.49it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6586246266961098 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 195.89it/s]\n",
      "EP:33 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.13it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6538198068737984 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.76it/s]\n",
      "EP:34 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.27it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6511841677129269 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 188.51it/s]\n",
      "EP:35 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.60it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6500145941972733 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.82it/s]\n",
      "EP:36 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.18it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6482172533869743 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.51it/s]\n",
      "EP:37 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.85it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6457022912800312 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 187.24it/s]\n",
      "EP:38 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.80it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6439419388771057 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 188.90it/s]\n",
      "EP:39 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.89it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6452203914523125 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 187.04it/s]\n",
      "EP:40 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.84it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6439455933868885 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.16it/s]\n",
      "EP:41 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.00it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6450448520481586 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 179.08it/s]\n",
      "EP:42 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 80.93it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.644328847527504 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.15it/s]\n",
      "EP:43 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.46it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.644280020147562 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.57it/s]\n",
      "EP:44 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.31it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6449641287326813 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.31it/s]\n",
      "EP:45 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.18it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.644275963306427 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.10it/s]\n",
      "EP:46 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.38it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6460611335933208 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 184.87it/s]\n",
      "EP:47 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.26it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6446578502655029 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.08it/s]\n",
      "EP:48 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.25it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6463088318705559 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.02it/s]\n",
      "EP:49 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.85it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6461150608956814 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.26it/s]\n",
      "EP:50 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.91it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6462475247681141 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 179.18it/s]\n",
      "EP:51 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.79it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.64782590046525 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 184.03it/s]\n",
      "EP:52 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.70it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6477078348398209 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 185.56it/s]\n",
      "EP:53 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.77it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6474572457373142 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 164.81it/s]\n",
      "EP:54 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.06it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6463081501424313 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 191.86it/s]\n",
      "EP:55 | lr: 1e-05:  44%|| 7/16 [00:00<00:00, 69.98it/s]\n",
      "EP_train | avg_loss: 0.6482763439416885 |\n",
      "EP:55 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 77.79it/s]\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.88it/s]\n",
      "EP:56 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.49it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.648335475474596 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.60it/s]\n",
      "EP:57 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.33it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6485736072063446 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.38it/s]\n",
      "EP:58 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 82.96it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6486358232796192 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.52it/s]\n",
      "EP:59 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.73it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6479662209749222 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.19it/s]\n",
      "EP:60 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.52it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6484405845403671 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 195.39it/s]\n",
      "EP:61 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.19it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6492003053426743 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.94it/s]\n",
      "EP:62 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.50it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6502400524914265 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.06it/s]\n",
      "EP:63 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.84it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6492748409509659 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 195.52it/s]\n",
      "EP:64 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.41it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6492045857012272 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.55it/s]\n",
      "EP:65 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.92it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6493215896189213 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 187.63it/s]\n",
      "EP:66 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.03it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.648733526468277 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.42it/s]\n",
      "EP:67 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.67it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6482201814651489 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.09it/s]\n",
      "EP:68 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.58it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6483417637646198 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.11it/s]\n",
      "EP:69 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.42it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6480365954339504 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 188.61it/s]\n",
      "EP:70 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.13it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6468170210719109 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.46it/s]\n",
      "EP:71 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.21it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6475114300847054 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.18it/s]\n",
      "EP:72 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.35it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6466489173471928 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.93it/s]\n",
      "EP:73 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.65it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6474190764129162 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.53it/s]\n",
      "EP:74 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.79it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6476304419338703 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 182.50it/s]\n",
      "EP:75 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.50it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6460480466485023 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 187.88it/s]\n",
      "EP:76 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.47it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6455081067979336 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 182.22it/s]\n",
      "EP:77 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.76it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6467329487204552 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.70it/s]\n",
      "EP:78 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.38it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6457386240363121 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.00it/s]\n",
      "EP:79 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 83.83it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6463991962373257 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.52it/s]\n",
      "EP:80 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.47it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6451237220317125 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.61it/s]\n",
      "EP:81 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.07it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6448633149266243 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 185.71it/s]\n",
      "EP:82 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.99it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6448976248502731 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.89it/s]\n",
      "EP:83 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.75it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6450444348156452 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.83it/s]\n",
      "EP:84 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.78it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6436335071921349 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 185.20it/s]\n",
      "EP:85 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.36it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6427297852933407 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 191.59it/s]\n",
      "EP:86 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.43it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6433808468282223 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.09it/s]\n",
      "EP:87 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.55it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6432580649852753 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.79it/s]\n",
      "EP:88 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.74it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6429350487887859 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.35it/s]\n",
      "EP:89 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.50it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.641327504068613 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.38it/s]\n",
      "EP:90 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 80.61it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6413640826940536 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 183.89it/s]\n",
      "EP:91 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.38it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6413493528962135 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 191.00it/s]\n",
      "EP:92 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.65it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6413814425468445 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 189.42it/s]\n",
      "EP:93 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.03it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6402222774922848 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.49it/s]\n",
      "EP:94 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.36it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6388134397566319 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 194.16it/s]\n",
      "EP:95 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.08it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6400546245276928 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 192.68it/s]\n",
      "EP:96 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.24it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6388600654900074 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 193.18it/s]\n",
      "EP:97 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 85.69it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6382997557520866 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 190.44it/s]\n",
      "EP:98 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.75it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6385583803057671 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 186.34it/s]\n",
      "EP:99 | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 84.52it/s]\n",
      "EP: train | lr: 1e-05:   0%|| 0/16 [00:00<?, ?it/s]\n",
      "EP_train | avg_loss: 0.6375659443438053 |\n",
      "EP: train | lr: 1e-05: 100%|| 16/16 [00:00<00:00, 155.94it/s]\n",
      "EP_train | avg_loss: 0.6377907935529947 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP:0 | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  0,   0, 288,  ..., 526,   0,   0],\n",
      "        [849,  15, 458,  ...,   0,   8, 300],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([ 0.,  2., 13.,  7.,  4.,  3.,  2.,  1.,  1.,  2.,  5., 11.,  0.,  1.,\n",
      "         6.,  0.,  1.,  6.,  4.,  3.,  1.,  0.,  3.,  3.,  2.,  6.,  0.,  2.,\n",
      "         9.,  4., 12.,  7.,  6.,  1.,  1.,  2.,  3.,  1.,  3.,  5., 11.,  5.,\n",
      "         2.,  9., 11.,  0.,  1.,  6.,  0.,  0.,  8.,  1.,  5.,  0.,  9.,  4.,\n",
      "        13.,  3.,  2.,  2.,  1.,  3.,  0.,  6.], device='cuda:0')\n",
      "tensor([[[ 6.0121e-01],\n",
      "         [ 3.5993e-01],\n",
      "         [ 2.6935e-01],\n",
      "         ...,\n",
      "         [ 9.3061e-01],\n",
      "         [ 6.7218e-01],\n",
      "         [ 5.9746e-01]],\n",
      "\n",
      "        [[ 5.3440e-01],\n",
      "         [ 5.7120e-01],\n",
      "         [ 9.3283e-01],\n",
      "         ...,\n",
      "         [ 2.4973e-01],\n",
      "         [ 4.3619e-01],\n",
      "         [ 9.2209e-01]],\n",
      "\n",
      "        [[ 9.8335e-01],\n",
      "         [ 3.1896e-01],\n",
      "         [ 4.8618e-01],\n",
      "         ...,\n",
      "         [ 6.4320e-01],\n",
      "         [ 8.7757e-01],\n",
      "         [ 4.3513e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.3695e-01],\n",
      "         [ 6.3075e-01],\n",
      "         [-3.0097e-02],\n",
      "         ...,\n",
      "         [ 5.4032e-01],\n",
      "         [ 3.4146e-02],\n",
      "         [ 3.6431e-01]],\n",
      "\n",
      "        [[ 9.0569e-02],\n",
      "         [ 3.6251e-01],\n",
      "         [ 1.3408e-01],\n",
      "         ...,\n",
      "         [ 1.3202e-04],\n",
      "         [ 5.2705e-01],\n",
      "         [ 3.9068e-01]],\n",
      "\n",
      "        [[ 4.9548e-01],\n",
      "         [ 4.6397e-01],\n",
      "         [ 5.6939e-01],\n",
      "         ...,\n",
      "         [ 6.6638e-01],\n",
      "         [ 4.2747e-01],\n",
      "         [ 7.1454e-01]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([128, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 1])\n",
      "25.996700286865234\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bb6f4c62359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# self.scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattractive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# NLLLoss of predicting masked token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP:0 | lr: 0.001:   0%|| 0/32 [00:00<?, ?it/s]tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [ 48, 241,   0,  ...,   0, 805,   0],\n",
      "        [211,   3,   0,  ...,   0,  13, 303],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([ 4.,  1.,  2.,  2.,  0., 13.,  3.,  9.,  1.,  1.,  3.,  3.,  2.,  1.,\n",
      "         2.,  2.,  0.,  8.,  1.,  9.,  0.,  1.,  0.,  3.,  6., 10.,  2.,  7.,\n",
      "         4.,  1.,  2.,  2.,  6.,  6.,  2., 14.,  2.,  3.,  7.,  0.,  4.,  3.,\n",
      "         1., 13.,  0.,  0.,  1.,  1.,  1.,  0.,  4.,  2.,  5.,  1.,  3.,  5.,\n",
      "         0.,  2.,  0.,  8.,  1.,  0.,  9.,  1.], device='cuda:0')\n",
      "tensor([[-0.2539],\n",
      "        [-0.8596],\n",
      "        [-1.1908],\n",
      "        [-1.5457],\n",
      "        [-0.2728],\n",
      "        [-0.9879],\n",
      "        [-0.8742],\n",
      "        [-1.1552],\n",
      "        [-1.1962],\n",
      "        [-1.4770],\n",
      "        [-0.5963],\n",
      "        [-1.6508],\n",
      "        [-0.5904],\n",
      "        [-1.2092],\n",
      "        [-1.4268],\n",
      "        [-0.2909],\n",
      "        [-0.8780],\n",
      "        [-0.6749],\n",
      "        [-1.1115],\n",
      "        [-0.8630],\n",
      "        [-0.9790],\n",
      "        [-0.7880],\n",
      "        [-0.8269],\n",
      "        [-1.3190],\n",
      "        [-1.4739],\n",
      "        [-1.3425],\n",
      "        [-1.2339],\n",
      "        [-1.1160],\n",
      "        [-1.2770],\n",
      "        [-1.3377],\n",
      "        [-1.7300],\n",
      "        [-1.4053],\n",
      "        [-1.4985],\n",
      "        [-1.3642],\n",
      "        [-1.3358],\n",
      "        [-0.9606],\n",
      "        [-1.2042],\n",
      "        [-1.6164],\n",
      "        [-1.3799],\n",
      "        [-1.1898],\n",
      "        [-1.4967],\n",
      "        [-1.4721],\n",
      "        [-1.7613],\n",
      "        [-1.1037],\n",
      "        [-1.0040],\n",
      "        [-1.5401],\n",
      "        [-1.0843],\n",
      "        [-0.8682],\n",
      "        [-1.2682],\n",
      "        [-1.1550],\n",
      "        [-1.3988],\n",
      "        [-1.3398],\n",
      "        [-1.3936],\n",
      "        [-1.7836],\n",
      "        [-1.6804],\n",
      "        [-1.3008],\n",
      "        [-1.5489],\n",
      "        [-1.1335],\n",
      "        [-1.3884],\n",
      "        [-1.5549],\n",
      "        [-1.2522],\n",
      "        [-1.0548],\n",
      "        [-1.2672],\n",
      "        [-1.3845],\n",
      "        [-1.4811],\n",
      "        [-1.4342],\n",
      "        [-1.3536],\n",
      "        [-1.1534],\n",
      "        [-1.1998],\n",
      "        [-1.2637],\n",
      "        [-1.5077],\n",
      "        [-1.4890],\n",
      "        [-1.3994],\n",
      "        [-1.1649],\n",
      "        [-1.4032],\n",
      "        [-1.4273],\n",
      "        [-1.5072],\n",
      "        [-1.2913],\n",
      "        [-1.4187],\n",
      "        [-1.5821],\n",
      "        [-1.1610],\n",
      "        [-1.1004],\n",
      "        [-1.0985],\n",
      "        [-0.8344],\n",
      "        [-1.6426],\n",
      "        [-1.0117],\n",
      "        [-0.9649],\n",
      "        [-1.3412],\n",
      "        [-1.1632],\n",
      "        [-1.0748],\n",
      "        [-1.5117],\n",
      "        [-1.1857],\n",
      "        [-1.3199],\n",
      "        [-1.0420],\n",
      "        [-1.3646],\n",
      "        [-1.2566],\n",
      "        [-1.3299],\n",
      "        [-1.3563],\n",
      "        [-1.5357],\n",
      "        [-1.5247],\n",
      "        [-1.0464],\n",
      "        [-1.2225],\n",
      "        [-1.3271],\n",
      "        [-1.2447],\n",
      "        [-1.9028],\n",
      "        [-1.4855],\n",
      "        [-1.5180],\n",
      "        [-1.4581],\n",
      "        [-1.5808],\n",
      "        [-1.3883],\n",
      "        [-1.2648],\n",
      "        [-1.0551],\n",
      "        [-1.5557],\n",
      "        [-1.3459],\n",
      "        [-0.9999],\n",
      "        [-1.5748],\n",
      "        [-1.5305],\n",
      "        [-1.3661],\n",
      "        [-1.4075],\n",
      "        [-1.0807],\n",
      "        [-1.1934],\n",
      "        [-1.7515],\n",
      "        [-1.5570],\n",
      "        [-1.5616],\n",
      "        [-1.4749],\n",
      "        [-1.3812],\n",
      "        [-0.9541],\n",
      "        [-1.5316]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([128, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 1])\n",
      "32.67628479003906\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bb6f4c62359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# self.scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattractive_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattractive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# NLLLoss of predicting masked token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence):\n",
    "    tokens = AttractiveData.tokenizer(sentence)\n",
    "    indexed = [AttractiveData.TEXT.vocab.stoi[t] for t in tokens]\n",
    "    # print(indexed)\n",
    "    tensor = torch.LongTensor(indexed).to(AttractiveData.device)\n",
    "\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    # print(tensor.shape)\n",
    "    prediction = AttractiveTrainer.model(tensor)\n",
    "\n",
    "    # print(prediction.shape)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.964232921600342"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "a = \"Cancer left Eric With half his face missing and unable to eat or drink. now surgeons have made him a new face using a 3d printer\"\n",
    "prediction = predict_attractive(a)\n",
    "prediction.item()"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'Text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c5e00d7c3c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             self.batches = batch(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    252\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/attractivedata.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATEGORIES_LABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         self.trainloader, self.testloader = data.BucketIterator.splits(\n\u001b[1;32m     38\u001b[0m             (self.train_data, self.test_data), sort_key=lambda x: len(x.Text), batch_size=batch_size, device=self.device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "next(iter(AttractiveData.testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_headline = AttractiveData.df_test['Headline'].to_list()\n",
    "predict_list = []\n",
    "for i in range(len(test_headline)):\n",
    "    predict_list.append(predict_attractive(test_headline[i]).item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}