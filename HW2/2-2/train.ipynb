{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.840B.300d'\n",
    "config = {\n",
    "    'max_size': 48,\n",
    "    'min_freq': 5,\n",
    "    'batch_size': 64,\n",
    "    'pretrained_file': pretrained_file\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '0.18333333333333313'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "max_len = 0\n",
    "a = AttractiveData.train_data\n",
    "for i in range(len(a)):\n",
    "    if len(a[i].Headline) >= max_len:\n",
    "        max_len = len(a[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1518, 300])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 10\n",
    "\n",
    "config['timestr'] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['save_name'] = 'LSTM'\n",
    "config['input_dim'] = len(AttractiveData.TEXT.vocab)\n",
    "config['embedding_dim'] = 300\n",
    "config['category_dim'] = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "config['category_embedding_dim'] = 16\n",
    "config['hidden_dim'] = 128\n",
    "config['output_dim'] = 1\n",
    "config['log_steps'] = 10\n",
    "config['epochs'] = 20\n",
    "config['lr'] = {\n",
    "    'encoder': 3e-5,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-4\n",
    "}\n",
    "config['num_layers'] = 1\n",
    "config['nhead'] = 4\n",
    "config['kernel_size'] = 3\n",
    "config['dropout'] = 0.1\n",
    "\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(config, AttractiveData.device, AttractiveData.trainloader, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(AttractiveNet(\n",
       "   (embedding): AttractiveEmbedding(\n",
       "     (token): TokenEmbedding(1518, 300, padding_idx=1)\n",
       "   )\n",
       "   (encoder): LSTM(300, 128, dropout=0.1, bidirectional=True)\n",
       "   (linear_output): Linear(in_features=256, out_features=1, bias=True)\n",
       " ),\n",
       " 895977,\n",
       " 440577)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "AttractiveTrainer.model, AttractiveTrainer.config['total_params'], AttractiveTrainer.config['total_learned_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:00<00:05,  3.68it/s]\n",
      "EP_train | avg_loss: 0.5334173962473869 |\n",
      "Epoch:  10%|█         | 2/20 [00:00<00:04,  3.85it/s]\n",
      "EP_train | avg_loss: 0.5322569962590933 |\n",
      "Epoch:  15%|█▌        | 3/20 [00:00<00:04,  4.01it/s]\n",
      "EP_train | avg_loss: 0.5322300931438804 |\n",
      "Epoch:  20%|██        | 4/20 [00:00<00:03,  4.18it/s]\n",
      "EP_train | avg_loss: 0.532259282656014 |\n",
      "Epoch:  25%|██▌       | 5/20 [00:01<00:03,  4.20it/s]\n",
      "EP_train | avg_loss: 0.5320576746016741 |\n",
      "Epoch:  30%|███       | 6/20 [00:01<00:03,  4.15it/s]\n",
      "EP_train | avg_loss: 0.5327534331008792 |\n",
      "Epoch:  35%|███▌      | 7/20 [00:01<00:03,  4.25it/s]\n",
      "EP_train | avg_loss: 0.5323472563177347 |\n",
      "Epoch:  40%|████      | 8/20 [00:01<00:02,  4.33it/s]\n",
      "EP_train | avg_loss: 0.5331293186172843 |\n",
      "Epoch:  45%|████▌     | 9/20 [00:02<00:02,  4.39it/s]\n",
      "EP_train | avg_loss: 0.5324353026226163 |\n",
      "Epoch:  50%|█████     | 10/20 [00:02<00:02,  4.43it/s]\n",
      "EP_train | avg_loss: 0.5323125496506691 |\n",
      "Epoch:  55%|█████▌    | 11/20 [00:02<00:02,  4.48it/s]\n",
      "EP_train | avg_loss: 0.5322478199377656 |\n",
      "Epoch:  60%|██████    | 12/20 [00:02<00:01,  4.43it/s]\n",
      "EP_train | avg_loss: 0.532805135473609 |\n",
      "Epoch:  65%|██████▌   | 13/20 [00:02<00:01,  4.37it/s]\n",
      "EP_train | avg_loss: 0.5323826391249895 |\n",
      "Epoch:  70%|███████   | 14/20 [00:03<00:01,  4.39it/s]\n",
      "EP_train | avg_loss: 0.5324480207636952 |\n",
      "Epoch:  75%|███████▌  | 15/20 [00:03<00:01,  4.35it/s]\n",
      "EP_train | avg_loss: 0.5322426427155733 |\n",
      "Epoch:  80%|████████  | 16/20 [00:03<00:00,  4.38it/s]\n",
      "EP_train | avg_loss: 0.5316930580884218 |\n",
      "Epoch:  85%|████████▌ | 17/20 [00:03<00:00,  4.34it/s]\n",
      "EP_train | avg_loss: 0.5319944331422448 |\n",
      "Epoch:  90%|█████████ | 18/20 [00:04<00:00,  4.36it/s]\n",
      "EP_train | avg_loss: 0.5322462730109692 |\n",
      "Epoch:  95%|█████████▌| 19/20 [00:04<00:00,  4.30it/s]\n",
      "EP_train | avg_loss: 0.5325899571180344 |\n",
      "Epoch: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s]\n",
      "EP_train | avg_loss: 0.5322616826742887 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5601443355119825"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# a = AttractiveTrainer.train_predict\n",
    "# AttractiveData.LABEL.vocab.itos[int(a[0])], AttractiveTrainer.train_true[0]\n",
    "# correct = 0\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "# for i in range(len(a)):\n",
    "#     pred = AttractiveData.LABEL.vocab.itos[int(a[i])]\n",
    "#     pred_list.append(float(pred))\n",
    "#     true = AttractiveData.LABEL.vocab.itos[int(AttractiveTrainer.train_true[i])]\n",
    "#     true_list.append(float(true))\n",
    "# mean_squared_error(true_list, pred_list)\n",
    "# # true_list"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1518, 300, padding_idx=1)\n",
       "  )\n",
       "  (encoder): LSTM(300, 128, dropout=0.1, bidirectional=True)\n",
       "  (linear_output): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from attractivenet import AttractiveNet\n",
    "PATH = './model/LSTM_20201031-194214_0.5323.20'\n",
    "# load_model = TransformerModel(config).to(AttractiveData.device)\n",
    "load_model = AttractiveNet(config).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    if len(sentence) < config['max_size']:\n",
    "        sentence += ['0'] * (config['max_size'] - len(sentence))\n",
    "    else:\n",
    "        sentence = sentence[:config['max_size']]\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "predict_list = []\n",
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    predict_list.append(prediction.item() + 2.8)\n",
    "    # predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv(config['save_name'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "# test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "# for each_test in test_category:\n",
    "#     if each_test not in train_category:\n",
    "#         print(each_test)\n",
    "# print()\n",
    "# for each_train in train_category:\n",
    "#     if each_train not in test_category:\n",
    "#         print(each_train)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5275844079046633, 3.144413550989246, 0.01213976555398827)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "train_list = []\n",
    "for i, sentence in enumerate(AttractiveData.train_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    train_list.append(prediction.item() + 3.15)\n",
    "    # train_list.append(prediction.item())\n",
    "mean_squared_error(pd.read_csv('data/train.csv').sort_values(['ID']).Label.to_list(), train_list), statistics.mean(train_list), statistics.stdev(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0004084967320261136, 0.7295015193216009)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "a = AttractiveData.df_train['Label'].to_list()\n",
    "statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.7907568613239584, 0.013064209406311998)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.08929560530168232, 2.7156126782757597, 0.29355123275379763)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "baseline_list = pd.read_csv('baseline.csv').sort_values(['ID']).Label.to_list()\n",
    "mean_squared_error(baseline_list, predict_list), statistics.mean(baseline_list), statistics.stdev(baseline_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.8167915543795683, 0.14611407210842048)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# LSTM my best\n",
    "# statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}