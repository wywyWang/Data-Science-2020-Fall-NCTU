{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit",
   "display_name": "Python 3.6.12 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(123)\n",
    "# torch.cuda.manual_seed(123)\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'example/train.csv'\n",
    "test_file = 'example/val.csv'\n",
    "pretrained_file = 'glove.840B.300d'\n",
    "config = {\n",
    "    'max_seq': 40,\n",
    "    'min_freq': 0,\n",
    "    'batch_size': 64,\n",
    "    'pretrained_file': pretrained_file\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, sentence in enumerate(AttractiveData.test_data):\n",
    "#     if i == 3:\n",
    "#         print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "max_len = 0\n",
    "a = AttractiveData.train_data\n",
    "for i in range(len(a)):\n",
    "    if len(a[i].Headline) >= max_len:\n",
    "        max_len = len(a[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([12304, 300])\n"
     ]
    }
   ],
   "source": [
    "config['timestr'] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['save_name'] = 'CNN_LSTM'\n",
    "config['input_dim'] = len(AttractiveData.TEXT.vocab)\n",
    "config['embedding_dim'] = 300\n",
    "config['category_dim'] = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "config['category_embedding_dim'] = 16\n",
    "config['hidden_dim'] = 30\n",
    "config['output_dim'] = 1\n",
    "config['log_steps'] = 10\n",
    "config['epochs'] = 100\n",
    "config['lr'] = {\n",
    "    'encoder': 1e-5,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-5\n",
    "}\n",
    "config['num_layers'] = 1\n",
    "config['kernel_size'] = 3\n",
    "config['dropout'] = 0.1\n",
    "config['train_len'] = AttractiveData.train_len\n",
    "config['val_len'] = AttractiveData.val_len\n",
    "config['test_len'] = AttractiveData.test_len\n",
    "\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(config, AttractiveData.device, AttractiveData.trainloader, AttractiveData.valloader, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(AttractiveNet(\n",
       "   (embedding): AttractiveEmbedding(\n",
       "     (token): TokenEmbedding(12304, 300, padding_idx=1)\n",
       "   )\n",
       "   (cnn1): Sequential(\n",
       "     (0): Conv1d(300, 220, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (cnn2): Sequential(\n",
       "     (0): Conv1d(220, 150, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (cnn3): Sequential(\n",
       "     (0): Conv1d(150, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (encoder): LSTM(100, 30, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "   (linear): Sequential(\n",
       "     (0): Linear(in_features=120, out_features=30, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " 4069011,\n",
       " 377811)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model, AttractiveTrainer.config['total_params'], AttractiveTrainer.config['total_learned_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]====\n",
      "Epoch:   1%|          | 1/100 [00:00<00:22,  4.33it/s]\n",
      "EP_train | train loss: 0.5312445761618599 | val loss: 0.5414973988252527 |\n",
      "====\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:21,  4.47it/s]\n",
      "EP_train | train loss: 0.5311497962880799 | val loss: 0.5416066973817115 |\n",
      "====\n",
      "Epoch:   3%|▎         | 3/100 [00:00<00:21,  4.54it/s]\n",
      "EP_train | train loss: 0.5311221741793448 | val loss: 0.5416989419974533 |\n",
      "====\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:20,  4.62it/s]\n",
      "EP_train | train loss: 0.531097317627709 | val loss: 0.5415267009361118 |\n",
      "====\n",
      "Epoch:   5%|▌         | 5/100 [00:01<00:20,  4.63it/s]\n",
      "EP_train | train loss: 0.5310694903166056 | val loss: 0.5416466395060221 |\n",
      "====\n",
      "Epoch:   6%|▌         | 6/100 [00:01<00:20,  4.62it/s]\n",
      "EP_train | train loss: 0.5310537689610532 | val loss: 0.5413017833934111 |\n",
      "====\n",
      "Epoch:   7%|▋         | 7/100 [00:01<00:20,  4.63it/s]\n",
      "EP_train | train loss: 0.5309667666014996 | val loss: 0.5415950101964614 |\n",
      "====\n",
      "Epoch:   8%|▊         | 8/100 [00:01<00:19,  4.65it/s]\n",
      "EP_train | train loss: 0.5309696741271437 | val loss: 0.5412962670419731 |\n",
      "====\n",
      "Epoch:   9%|▉         | 9/100 [00:01<00:19,  4.67it/s]\n",
      "EP_train | train loss: 0.5309397861807462 | val loss: 0.5416481354657341 |\n",
      "====\n",
      "Epoch:  10%|█         | 10/100 [00:02<00:19,  4.60it/s]\n",
      "EP_train | train loss: 0.5308696798003741 | val loss: 0.5417410906623391 |\n",
      "====\n",
      "Epoch:  11%|█         | 11/100 [00:02<00:20,  4.44it/s]\n",
      "EP_train | train loss: 0.5308168483100316 | val loss: 0.5411957572488224 |\n",
      "====\n",
      "Epoch:  12%|█▏        | 12/100 [00:02<00:20,  4.39it/s]\n",
      "EP_train | train loss: 0.5308123245081788 | val loss: 0.5415793026194853 |\n",
      "====\n",
      "Epoch:  13%|█▎        | 13/100 [00:02<00:19,  4.44it/s]\n",
      "EP_train | train loss: 0.5308098581430221 | val loss: 0.5408493116790173 |\n",
      "====\n",
      "Epoch:  14%|█▍        | 14/100 [00:03<00:19,  4.32it/s]\n",
      "EP_train | train loss: 0.5306889604857832 | val loss: 0.5411956824508368 |\n",
      "====\n",
      "Epoch:  15%|█▌        | 15/100 [00:03<00:19,  4.39it/s]\n",
      "EP_train | train loss: 0.530714187336657 | val loss: 0.5416095584046607 |\n",
      "====\n",
      "Epoch:  16%|█▌        | 16/100 [00:03<00:18,  4.51it/s]\n",
      "EP_train | train loss: 0.5307019089028562 | val loss: 0.5407969530890969 |\n",
      "====\n",
      "Epoch:  17%|█▋        | 17/100 [00:03<00:18,  4.58it/s]\n",
      "EP_train | train loss: 0.5305776962677884 | val loss: 0.5410776699290556 |\n",
      "====\n",
      "Epoch:  18%|█▊        | 18/100 [00:03<00:17,  4.57it/s]\n",
      "EP_train | train loss: 0.5305824698063365 | val loss: 0.5415374344470454 |\n",
      "====\n",
      "Epoch:  19%|█▉        | 19/100 [00:04<00:17,  4.62it/s]\n",
      "EP_train | train loss: 0.5304939737014849 | val loss: 0.5408661786247703 |\n",
      "====\n",
      "Epoch:  20%|██        | 20/100 [00:04<00:17,  4.69it/s]\n",
      "EP_train | train loss: 0.5304555021941477 | val loss: 0.540918275421741 |\n",
      "====\n",
      "Epoch:  21%|██        | 21/100 [00:04<00:16,  4.70it/s]\n",
      "EP_train | train loss: 0.530408310078246 | val loss: 0.5411939433976716 |\n",
      "====\n",
      "Epoch:  22%|██▏       | 22/100 [00:04<00:16,  4.70it/s]\n",
      "EP_train | train loss: 0.5303334707569166 | val loss: 0.5407673330867991 |\n",
      "====\n",
      "Epoch:  23%|██▎       | 23/100 [00:05<00:16,  4.73it/s]\n",
      "EP_train | train loss: 0.5303157190297287 | val loss: 0.5405202379413679 |\n",
      "====\n",
      "Epoch:  24%|██▍       | 24/100 [00:05<00:16,  4.68it/s]\n",
      "EP_train | train loss: 0.5302309143530941 | val loss: 0.5405754201552447 |\n",
      "====\n",
      "Epoch:  25%|██▌       | 25/100 [00:05<00:15,  4.69it/s]\n",
      "EP_train | train loss: 0.5301897050918564 | val loss: 0.5407024832332835 |\n",
      "====\n",
      "Epoch:  27%|██▋       | 27/100 [00:05<00:15,  4.80it/s]\n",
      "EP_train | train loss: 0.5301277290556822 | val loss: 0.5409134509516698 |\n",
      "====\n",
      "\n",
      "EP_train | train loss: 0.5300675995947776 | val loss: 0.5405555799895642 |\n",
      "====\n",
      "Epoch:  28%|██▊       | 28/100 [00:06<00:15,  4.79it/s]\n",
      "EP_train | train loss: 0.5300046782498512 | val loss: 0.5403674069572898 |\n",
      "====\n",
      "Epoch:  29%|██▉       | 29/100 [00:06<00:15,  4.66it/s]\n",
      "EP_train | train loss: 0.5299349672654096 | val loss: 0.5403334112728343 |\n",
      "====\n",
      "Epoch:  30%|███       | 30/100 [00:06<00:15,  4.59it/s]\n",
      "EP_train | train loss: 0.5298722968874086 | val loss: 0.5406266941743738 |\n",
      "====\n",
      "Epoch:  31%|███       | 31/100 [00:06<00:14,  4.64it/s]\n",
      "EP_train | train loss: 0.5297961724677938 | val loss: 0.5403586742924709 |\n",
      "====\n",
      "Epoch:  32%|███▏      | 32/100 [00:06<00:14,  4.61it/s]\n",
      "EP_train | train loss: 0.5297260333633029 | val loss: 0.5402620539945715 |\n",
      "====\n",
      "Epoch:  33%|███▎      | 33/100 [00:07<00:14,  4.65it/s]\n",
      "EP_train | train loss: 0.5296735384638956 | val loss: 0.5406872618432138 |\n",
      "====\n",
      "Epoch:  34%|███▍      | 34/100 [00:07<00:14,  4.66it/s]\n",
      "EP_train | train loss: 0.5295946723536441 | val loss: 0.5399593278473499 |\n",
      "====\n",
      "Epoch:  35%|███▌      | 35/100 [00:07<00:14,  4.61it/s]\n",
      "EP_train | train loss: 0.5294824460957688 | val loss: 0.5401276607139438 |\n",
      "====\n",
      "Epoch:  36%|███▌      | 36/100 [00:07<00:13,  4.61it/s]\n",
      "EP_train | train loss: 0.5294438510733369 | val loss: 0.5404208875169941 |\n",
      "====\n",
      "Epoch:  37%|███▋      | 37/100 [00:08<00:13,  4.64it/s]\n",
      "EP_train | train loss: 0.5293498002338705 | val loss: 0.5396657270543715 |\n",
      "====\n",
      "Epoch:  38%|███▊      | 38/100 [00:08<00:13,  4.72it/s]\n",
      "EP_train | train loss: 0.5292248937490678 | val loss: 0.540040090972302 |\n",
      "====\n",
      "Epoch:  39%|███▉      | 39/100 [00:08<00:12,  4.76it/s]\n",
      "EP_train | train loss: 0.529140502429722 | val loss: 0.5397268183091107 |\n",
      "====\n",
      "Epoch:  40%|████      | 40/100 [00:08<00:12,  4.77it/s]\n",
      "EP_train | train loss: 0.529015394433241 | val loss: 0.5397948844760072 |\n",
      "====\n",
      "Epoch:  41%|████      | 41/100 [00:08<00:12,  4.83it/s]\n",
      "EP_train | train loss: 0.5289396048822393 | val loss: 0.539682575300628 |\n",
      "====\n",
      "Epoch:  42%|████▏     | 42/100 [00:09<00:11,  4.85it/s]\n",
      "EP_train | train loss: 0.5288353000755035 | val loss: 0.5394851086186427 |\n",
      "====\n",
      "Epoch:  43%|████▎     | 43/100 [00:09<00:11,  4.87it/s]\n",
      "EP_train | train loss: 0.5286903263245574 | val loss: 0.5393476299211091 |\n",
      "====\n",
      "Epoch:  44%|████▍     | 44/100 [00:09<00:11,  4.85it/s]\n",
      "EP_train | train loss: 0.5285704460675502 | val loss: 0.5393852159088733 |\n",
      "====\n",
      "Epoch:  45%|████▌     | 45/100 [00:09<00:11,  4.71it/s]\n",
      "EP_train | train loss: 0.5284527054266048 | val loss: 0.5390466428270527 |\n",
      "====\n",
      "Epoch:  46%|████▌     | 46/100 [00:09<00:11,  4.66it/s]\n",
      "EP_train | train loss: 0.5283218675107533 | val loss: 0.5391229180728688 |\n",
      "====\n",
      "Epoch:  47%|████▋     | 47/100 [00:10<00:11,  4.65it/s]\n",
      "EP_train | train loss: 0.528180014115246 | val loss: 0.5391859166762408 |\n",
      "====\n",
      "Epoch:  48%|████▊     | 48/100 [00:10<00:11,  4.55it/s]\n",
      "EP_train | train loss: 0.5280377975558349 | val loss: 0.5387460671219171 |\n",
      "====\n",
      "Epoch:  49%|████▉     | 49/100 [00:10<00:11,  4.61it/s]\n",
      "EP_train | train loss: 0.5278640575822293 | val loss: 0.5387106128767425 |\n",
      "====\n",
      "Epoch:  50%|█████     | 50/100 [00:10<00:10,  4.63it/s]\n",
      "EP_train | train loss: 0.5277081785802379 | val loss: 0.5385281057918773 |\n",
      "====\n",
      "Epoch:  51%|█████     | 51/100 [00:10<00:10,  4.65it/s]\n",
      "EP_train | train loss: 0.527525593744835 | val loss: 0.5383746951234107 |\n",
      "====\n",
      "Epoch:  52%|█████▏    | 52/100 [00:11<00:10,  4.70it/s]\n",
      "EP_train | train loss: 0.5273531957061421 | val loss: 0.5386518216600605 |\n",
      "====\n",
      "Epoch:  53%|█████▎    | 53/100 [00:11<00:09,  4.77it/s]\n",
      "EP_train | train loss: 0.5271061601038441 | val loss: 0.5381631103216433 |\n",
      "====\n",
      "Epoch:  54%|█████▍    | 54/100 [00:11<00:09,  4.74it/s]\n",
      "EP_train | train loss: 0.5268981754472258 | val loss: 0.5383921791525448 |\n",
      "====\n",
      "Epoch:  55%|█████▌    | 55/100 [00:11<00:09,  4.77it/s]\n",
      "EP_train | train loss: 0.5266551577761939 | val loss: 0.5376077726775524 |\n",
      "====\n",
      "Epoch:  56%|█████▌    | 56/100 [00:12<00:09,  4.75it/s]\n",
      "EP_train | train loss: 0.526396302123803 | val loss: 0.5377987880332797 |\n",
      "====\n",
      "Epoch:  57%|█████▋    | 57/100 [00:12<00:09,  4.72it/s]\n",
      "EP_train | train loss: 0.526111783380971 | val loss: 0.537361275916006 |\n",
      "====\n",
      "Epoch:  58%|█████▊    | 58/100 [00:12<00:08,  4.72it/s]\n",
      "EP_train | train loss: 0.525843948525664 | val loss: 0.5368144465427772 |\n",
      "====\n",
      "Epoch:  59%|█████▉    | 59/100 [00:12<00:08,  4.78it/s]\n",
      "EP_train | train loss: 0.5254877231192416 | val loss: 0.5368165782853669 |\n",
      "====\n",
      "Epoch:  60%|██████    | 60/100 [00:12<00:08,  4.83it/s]\n",
      "EP_train | train loss: 0.5251572562691105 | val loss: 0.5363805808273017 |\n",
      "====\n",
      "Epoch:  61%|██████    | 61/100 [00:13<00:08,  4.84it/s]\n",
      "EP_train | train loss: 0.5247303088752109 | val loss: 0.5362482070922852 |\n",
      "====\n",
      "Epoch:  62%|██████▏   | 62/100 [00:13<00:07,  4.80it/s]\n",
      "EP_train | train loss: 0.5244046733844391 | val loss: 0.5363956152224073 |\n",
      "====\n",
      "Epoch:  63%|██████▎   | 63/100 [00:13<00:07,  4.80it/s]\n",
      "EP_train | train loss: 0.5239324461441907 | val loss: 0.5353059768676758 |\n",
      "====\n",
      "Epoch:  65%|██████▌   | 65/100 [00:13<00:07,  4.88it/s]\n",
      "EP_train | train loss: 0.5233933780461519 | val loss: 0.5353232552023495 |\n",
      "====\n",
      "\n",
      "EP_train | train loss: 0.5228279111801163 | val loss: 0.5348004359824985 |\n",
      "Epoch:  66%|██████▌   | 66/100 [00:14<00:06,  4.90it/s]====\n",
      "\n",
      "EP_train | train loss: 0.5223227944782521 | val loss: 0.5338571024876014 |\n",
      "====\n",
      "Epoch:  67%|██████▋   | 67/100 [00:14<00:06,  4.84it/s]\n",
      "EP_train | train loss: 0.5216017802802402 | val loss: 0.5340831606995826 |\n",
      "====\n",
      "Epoch:  68%|██████▊   | 68/100 [00:14<00:06,  4.85it/s]\n",
      "EP_train | train loss: 0.5208452911691892 | val loss: 0.533175973331227 |\n",
      "====\n",
      "Epoch:  69%|██████▉   | 69/100 [00:14<00:06,  4.82it/s]\n",
      "EP_train | train loss: 0.520047567946254 | val loss: 0.5327142453661152 |\n",
      "====\n",
      "Epoch:  70%|███████   | 70/100 [00:14<00:06,  4.86it/s]\n",
      "EP_train | train loss: 0.5191432029716248 | val loss: 0.531804739260206 |\n",
      "====\n",
      "Epoch:  71%|███████   | 71/100 [00:15<00:05,  4.88it/s]\n",
      "EP_train | train loss: 0.5181324464740891 | val loss: 0.5318697761086857 |\n",
      "====\n",
      "Epoch:  72%|███████▏  | 72/100 [00:15<00:05,  4.87it/s]\n",
      "EP_train | train loss: 0.5171242193294876 | val loss: 0.5297020930869907 |\n",
      "====\n",
      "Epoch:  73%|███████▎  | 73/100 [00:15<00:05,  4.89it/s]\n",
      "EP_train | train loss: 0.5157616268862635 | val loss: 0.5299845863791073 |\n",
      "====\n",
      "Epoch:  74%|███████▍  | 74/100 [00:15<00:05,  4.67it/s]\n",
      "EP_train | train loss: 0.5142779128839357 | val loss: 0.5286480959723977 |\n",
      "====\n",
      "Epoch:  75%|███████▌  | 75/100 [00:15<00:05,  4.74it/s]\n",
      "EP_train | train loss: 0.5126232534985301 | val loss: 0.5275688171386719 |\n",
      "====\n",
      "Epoch:  77%|███████▋  | 77/100 [00:16<00:04,  4.85it/s]\n",
      "EP_train | train loss: 0.5109489261796477 | val loss: 0.5261749940759995 |\n",
      "====\n",
      "\n",
      "EP_train | train loss: 0.5087987916511402 | val loss: 0.5248868231679878 |\n",
      "====\n",
      "Epoch:  78%|███████▊  | 78/100 [00:16<00:04,  4.88it/s]\n",
      "EP_train | train loss: 0.5065546958439121 | val loss: 0.5235961091284659 |\n",
      "====\n",
      "Epoch:  79%|███████▉  | 79/100 [00:16<00:04,  4.90it/s]\n",
      "EP_train | train loss: 0.5040346008828304 | val loss: 0.5217092177447151 |\n",
      "====\n",
      "Epoch:  80%|████████  | 80/100 [00:16<00:04,  4.88it/s]\n",
      "EP_train | train loss: 0.5009405571117735 | val loss: 0.5200102562997856 |\n",
      "====\n",
      "Epoch:  81%|████████  | 81/100 [00:17<00:03,  4.83it/s]\n",
      "EP_train | train loss: 0.49759601045811264 | val loss: 0.5176459293739468 |\n",
      "====\n",
      "Epoch:  82%|████████▏ | 82/100 [00:17<00:03,  4.79it/s]\n",
      "EP_train | train loss: 0.49362435429457907 | val loss: 0.515906296524347 |\n",
      "====\n",
      "Epoch:  83%|████████▎ | 83/100 [00:17<00:03,  4.69it/s]\n",
      "EP_train | train loss: 0.48962865402331907 | val loss: 0.5150802649703681 |\n",
      "====\n",
      "Epoch:  84%|████████▍ | 84/100 [00:17<00:03,  4.63it/s]\n",
      "EP_train | train loss: 0.4851052423994854 | val loss: 0.5102893137464336 |\n",
      "====\n",
      "Epoch:  85%|████████▌ | 85/100 [00:18<00:03,  4.68it/s]\n",
      "EP_train | train loss: 0.479772359102011 | val loss: 0.5095019901500029 |\n",
      "====\n",
      "Epoch:  86%|████████▌ | 86/100 [00:18<00:02,  4.73it/s]\n",
      "EP_train | train loss: 0.4743868568979427 | val loss: 0.5084811191932828 |\n",
      "====\n",
      "Epoch:  87%|████████▋ | 87/100 [00:18<00:02,  4.78it/s]\n",
      "EP_train | train loss: 0.46847382959812667 | val loss: 0.5057748439265233 |\n",
      "====\n",
      "Epoch:  89%|████████▉ | 89/100 [00:18<00:02,  4.87it/s]\n",
      "EP_train | train loss: 0.46250590057687985 | val loss: 0.5052913403978535 |\n",
      "====\n",
      "\n",
      "EP_train | train loss: 0.45622554184605585 | val loss: 0.5056788781109978 |\n",
      "====\n",
      "Epoch:  90%|█████████ | 90/100 [00:19<00:02,  4.81it/s]\n",
      "EP_train | train loss: 0.449474994120091 | val loss: 0.5016759797638538 |\n",
      "====\n",
      "Epoch:  91%|█████████ | 91/100 [00:19<00:01,  4.73it/s]\n",
      "EP_train | train loss: 0.44292760362812117 | val loss: 0.5017223732144225 |\n",
      "====\n",
      "Epoch:  92%|█████████▏| 92/100 [00:19<00:01,  4.73it/s]\n",
      "EP_train | train loss: 0.4366009899706294 | val loss: 0.5001639010859471 |\n",
      "====\n",
      "Epoch:  93%|█████████▎| 93/100 [00:19<00:01,  4.73it/s]\n",
      "EP_train | train loss: 0.4309164082671836 | val loss: 0.5039032300313314 |\n",
      "====\n",
      "Epoch:  94%|█████████▍| 94/100 [00:19<00:01,  4.79it/s]\n",
      "EP_train | train loss: 0.4248699595684607 | val loss: 0.5017165015725529 |\n",
      "====\n",
      "Epoch:  95%|█████████▌| 95/100 [00:20<00:01,  4.76it/s]\n",
      "EP_train | train loss: 0.41914210907568994 | val loss: 0.5012377570657169 |\n",
      "====\n",
      "Epoch:  96%|█████████▌| 96/100 [00:20<00:00,  4.75it/s]\n",
      "EP_train | train loss: 0.4143453594085725 | val loss: 0.49943938909792435 |\n",
      "====\n",
      "Epoch:  97%|█████████▋| 97/100 [00:20<00:00,  4.74it/s]\n",
      "EP_train | train loss: 0.41008159422899054 | val loss: 0.5060006870942957 |\n",
      "====\n",
      "Epoch:  98%|█████████▊| 98/100 [00:20<00:00,  4.66it/s]\n",
      "EP_train | train loss: 0.4050309872110562 | val loss: 0.49535352108525293 |\n",
      "====\n",
      "Epoch:  99%|█████████▉| 99/100 [00:21<00:00,  4.69it/s]\n",
      "EP_train | train loss: 0.4002492873169197 | val loss: 0.49635765599269493 |\n",
      "====\n",
      "Epoch: 100%|██████████| 100/100 [00:21<00:00,  4.72it/s]\n",
      "EP_train | train loss: 0.3962211451417275 | val loss: 0.49444739023844403 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(12304, 300, padding_idx=1)\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv1d(300, 220, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv1d(220, 150, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv1d(150, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (encoder): LSTM(100, 30, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=120, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from attractivenet import AttractiveNet\n",
    "PATH = './model/CNN_LSTM_20201101-164634_0.3962.100'\n",
    "# load_model = TransformerModel(config).to(AttractiveData.device)\n",
    "load_model = AttractiveNet(config).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category, phase):\n",
    "    # if len(sentence) < config['max_seq']:\n",
    "    #     sentence += ['0'] * (config['max_seq'] - len(sentence))\n",
    "    # else:\n",
    "    #     sentence = sentence[:config['max_seq']]\n",
    "\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(0)\n",
    "    # print(tensor_sentence.shape)\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category, phase=phase)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "predict_list = []\n",
    "with torch.no_grad():\n",
    "    for i, sentence in enumerate(AttractiveData.test_data):\n",
    "        prediction = predict_attractive(sentence.Headline, sentence.Category, 'test')\n",
    "        predict_list.append(prediction.item())\n",
    "        # predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv(config['save_name'] + '.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2040, 1938]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a00d1bd235cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# train_list.append(prediction.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(train_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \"\"\"\n\u001b[1;32m    255\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 256\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2040, 1938]"
     ]
    }
   ],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "train_list = []\n",
    "for i, sentence in enumerate(AttractiveData.train_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category, 'train')\n",
    "    train_list.append(prediction.item())\n",
    "    # train_list.append(prediction.item())\n",
    "# print(train_list)\n",
    "mean_squared_error(pd.read_csv('data/train.csv').sort_values(['ID']).Label.to_list(), train_list), statistics.mean(train_list), statistics.stdev(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list[0:5], pd.read_csv('data/train.csv').sort_values(['ID']).Label.to_list()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_train['Label'].to_list()\n",
    "statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.9698523624352946, 0.3498932131236277)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.11773663857161182, 2.7156126782757597, 0.29355123275379763)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "baseline_list = pd.read_csv('baseline.csv').sort_values(['ID']).Label.to_list()\n",
    "mean_squared_error(baseline_list, predict_list), statistics.mean(baseline_list), statistics.stdev(baseline_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.8167915543795683, 0.14611407210842048)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# LSTM my best\n",
    "# statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.1347375515605904, 2.8379913731293533, 0.1903582104725371)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "a = pd.read_csv('LSTM_base.csv').Label.to_list()\n",
    "mean_squared_error(baseline_list, a), statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "AttractiveData.TEXT.vocab.itos[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}