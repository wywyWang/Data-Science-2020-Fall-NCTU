{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit",
   "display_name": "Python 3.6.12 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'example/train.csv'\n",
    "test_file = 'example/test.csv'\n",
    "pretrained_file = 'glove.840B.300d'\n",
    "config = {\n",
    "    'max_seq': 40,\n",
    "    'min_freq': 0,\n",
    "    'batch_size': 64,\n",
    "    'pretrained_file': pretrained_file\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, sentence in enumerate(AttractiveData.test_data):\n",
    "#     if i == 3:\n",
    "#         print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "max_len = 0\n",
    "a = AttractiveData.train_data\n",
    "for i in range(len(a)):\n",
    "    if len(a[i].Headline) >= max_len:\n",
    "        max_len = len(a[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([11857, 300])\n"
     ]
    }
   ],
   "source": [
    "config['timestr'] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config['save_name'] = 'CNN_LSTM'\n",
    "config['input_dim'] = len(AttractiveData.TEXT.vocab)\n",
    "config['embedding_dim'] = 300\n",
    "config['category_dim'] = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "config['category_embedding_dim'] = 5\n",
    "config['hidden_dim'] = 30\n",
    "config['output_dim'] = 1\n",
    "config['log_steps'] = 10\n",
    "config['epochs'] = 200\n",
    "config['lr'] = {\n",
    "    'encoder': 6e-6,\n",
    "    'embedding': 6e-6,\n",
    "    'linear': 5e-6\n",
    "}\n",
    "config['num_layers'] = 1\n",
    "config['kernel_size'] = 3\n",
    "config['dropout'] = 0.1\n",
    "config['train_len'] = AttractiveData.train_len\n",
    "config['val_len'] = AttractiveData.val_len\n",
    "config['test_len'] = AttractiveData.test_len\n",
    "\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(config, AttractiveData.device, AttractiveData.trainloader, AttractiveData.valloader, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(AttractiveNet(\n",
       "   (embedding): AttractiveEmbedding(\n",
       "     (token): TokenEmbedding(11857, 300, padding_idx=1)\n",
       "   )\n",
       "   (bigramcnn): Sequential(\n",
       "     (0): Conv1d(300, 200, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (1): ReLU()\n",
       "     (2): Conv1d(200, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (trigramcnn): Sequential(\n",
       "     (0): Conv1d(300, 200, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (1): ReLU()\n",
       "     (2): Conv1d(200, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (encoder_bigram): LSTM(100, 30, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "   (encoder_trigram): LSTM(100, 30, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "   (linear): Sequential(\n",
       "     (0): Linear(in_features=120, out_features=30, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " 4104721,\n",
       " 4104721)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "AttractiveTrainer.model, AttractiveTrainer.config['total_params'], AttractiveTrainer.config['total_learned_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP_train | train loss: 0.5182991806977715 | val loss: 0.5112693356532677 |\n",
      "====\n",
      "Epoch:  28%|██▊       | 56/200 [00:12<00:33,  4.25it/s]\n",
      "EP_train | train loss: 0.5200491387859668 | val loss: 0.5088743883020738 |\n",
      "====\n",
      "Epoch:  28%|██▊       | 57/200 [00:13<00:33,  4.33it/s]\n",
      "EP_train | train loss: 0.5179222798814961 | val loss: 0.5072984321444642 |\n",
      "====\n",
      "Epoch:  29%|██▉       | 58/200 [00:13<00:32,  4.36it/s]\n",
      "EP_train | train loss: 0.5205483083371762 | val loss: 0.5052904054230335 |\n",
      "====\n",
      "Epoch:  30%|██▉       | 59/200 [00:13<00:32,  4.38it/s]\n",
      "EP_train | train loss: 0.5152244463985003 | val loss: 0.5014973621742398 |\n",
      "====\n",
      "Epoch:  30%|███       | 60/200 [00:13<00:31,  4.42it/s]\n",
      "EP_train | train loss: 0.5141798842187021 | val loss: 0.5027233853059656 |\n",
      "====\n",
      "Epoch:  30%|███       | 61/200 [00:13<00:32,  4.34it/s]\n",
      "EP_train | train loss: 0.5140327067157022 | val loss: 0.5012125875435623 |\n",
      "====\n",
      "Epoch:  31%|███       | 62/200 [00:14<00:31,  4.37it/s]\n",
      "EP_train | train loss: 0.5103291228965476 | val loss: 0.4991258733412799 |\n",
      "====\n",
      "Epoch:  32%|███▏      | 63/200 [00:14<00:31,  4.39it/s]\n",
      "EP_train | train loss: 0.5136815696500225 | val loss: 0.4975583319570504 |\n",
      "====\n",
      "Epoch:  32%|███▏      | 64/200 [00:14<00:30,  4.42it/s]\n",
      "EP_train | train loss: 0.5099269351668347 | val loss: 0.49333656535429116 |\n",
      "====\n",
      "Epoch:  32%|███▎      | 65/200 [00:14<00:30,  4.42it/s]\n",
      "EP_train | train loss: 0.5068791167149097 | val loss: 0.4928993711284563 |\n",
      "====\n",
      "Epoch:  33%|███▎      | 66/200 [00:15<00:31,  4.32it/s]\n",
      "EP_train | train loss: 0.5056984325899277 | val loss: 0.49074552573409735 |\n",
      "====\n",
      "Epoch:  34%|███▎      | 67/200 [00:15<00:30,  4.31it/s]\n",
      "EP_train | train loss: 0.5092171157886779 | val loss: 0.4929291313769771 |\n",
      "====\n",
      "Epoch:  34%|███▍      | 68/200 [00:15<00:30,  4.31it/s]\n",
      "EP_train | train loss: 0.5073542781904632 | val loss: 0.48516497892491955 |\n",
      "====\n",
      "Epoch:  34%|███▍      | 69/200 [00:15<00:30,  4.32it/s]\n",
      "EP_train | train loss: 0.5052789987302294 | val loss: 0.48525036082548256 |\n",
      "====\n",
      "Epoch:  35%|███▌      | 70/200 [00:16<00:29,  4.37it/s]\n",
      "EP_train | train loss: 0.5025234928837529 | val loss: 0.48460782742967795 |\n",
      "====\n",
      "Epoch:  36%|███▌      | 71/200 [00:16<00:30,  4.28it/s]\n",
      "EP_train | train loss: 0.5009006924099393 | val loss: 0.4783342305351706 |\n",
      "====\n",
      "Epoch:  36%|███▌      | 72/200 [00:16<00:29,  4.31it/s]\n",
      "EP_train | train loss: 0.4996745040993285 | val loss: 0.47892069349101946 |\n",
      "====\n",
      "Epoch:  36%|███▋      | 73/200 [00:16<00:29,  4.31it/s]\n",
      "EP_train | train loss: 0.4990213047185495 | val loss: 0.47835755815692976 |\n",
      "====\n",
      "Epoch:  37%|███▋      | 74/200 [00:16<00:29,  4.34it/s]\n",
      "EP_train | train loss: 0.49869577661318976 | val loss: 0.47305765338972505 |\n",
      "====\n",
      "Epoch:  38%|███▊      | 75/200 [00:17<00:28,  4.39it/s]\n",
      "EP_train | train loss: 0.499336573033551 | val loss: 0.4740901460834578 |\n",
      "====\n",
      "Epoch:  38%|███▊      | 76/200 [00:17<00:28,  4.32it/s]\n",
      "EP_train | train loss: 0.49263475455489814 | val loss: 0.4713544471591127 |\n",
      "====\n",
      "Epoch:  38%|███▊      | 77/200 [00:17<00:28,  4.31it/s]\n",
      "EP_train | train loss: 0.4933666112895625 | val loss: 0.4686442169488645 |\n",
      "====\n",
      "Epoch:  39%|███▉      | 78/200 [00:17<00:28,  4.34it/s]\n",
      "EP_train | train loss: 0.490193524911253 | val loss: 0.46794429479860794 |\n",
      "====\n",
      "Epoch:  40%|███▉      | 79/200 [00:18<00:27,  4.37it/s]\n",
      "EP_train | train loss: 0.4888938787456172 | val loss: 0.4629545959771848 |\n",
      "====\n",
      "Epoch:  40%|████      | 80/200 [00:18<00:27,  4.37it/s]\n",
      "EP_train | train loss: 0.48804662534094584 | val loss: 0.46160780214795877 |\n",
      "====\n",
      "Epoch:  40%|████      | 81/200 [00:18<00:27,  4.28it/s]\n",
      "EP_train | train loss: 0.4850758425810238 | val loss: 0.4616388339622348 |\n",
      "====\n",
      "Epoch:  41%|████      | 82/200 [00:18<00:27,  4.31it/s]\n",
      "EP_train | train loss: 0.48530281810718945 | val loss: 0.45850378859276864 |\n",
      "====\n",
      "Epoch:  42%|████▏     | 83/200 [00:19<00:26,  4.36it/s]\n",
      "EP_train | train loss: 0.48502240669233865 | val loss: 0.455259454016592 |\n",
      "====\n",
      "Epoch:  42%|████▏     | 84/200 [00:19<00:26,  4.36it/s]\n",
      "EP_train | train loss: 0.4852549770039411 | val loss: 0.4562063778147978 |\n",
      "====\n",
      "Epoch:  42%|████▎     | 85/200 [00:19<00:26,  4.39it/s]\n",
      "EP_train | train loss: 0.47891973358353757 | val loss: 0.44901417750938266 |\n",
      "====\n",
      "Epoch:  43%|████▎     | 86/200 [00:19<00:26,  4.32it/s]\n",
      "EP_train | train loss: 0.48129449275064573 | val loss: 0.4477286806293562 |\n",
      "====\n",
      "Epoch:  44%|████▎     | 87/200 [00:19<00:26,  4.34it/s]\n",
      "EP_train | train loss: 0.4755459953756893 | val loss: 0.44619355482213635 |\n",
      "====\n",
      "Epoch:  44%|████▍     | 88/200 [00:20<00:25,  4.35it/s]\n",
      "EP_train | train loss: 0.4756298085962765 | val loss: 0.4473885274400898 |\n",
      "====\n",
      "Epoch:  44%|████▍     | 89/200 [00:20<00:25,  4.30it/s]\n",
      "EP_train | train loss: 0.4740475008430564 | val loss: 0.4400181115842333 |\n",
      "====\n",
      "Epoch:  45%|████▌     | 90/200 [00:20<00:25,  4.36it/s]\n",
      "EP_train | train loss: 0.4728509065632207 | val loss: 0.4398169611014572 |\n",
      "====\n",
      "Epoch:  46%|████▌     | 91/200 [00:20<00:25,  4.28it/s]\n",
      "EP_train | train loss: 0.47164932575101165 | val loss: 0.43874361000809015 |\n",
      "====\n",
      "Epoch:  46%|████▌     | 92/200 [00:21<00:24,  4.33it/s]\n",
      "EP_train | train loss: 0.46876417733485404 | val loss: 0.43547334858015474 |\n",
      "====\n",
      "Epoch:  46%|████▋     | 93/200 [00:21<00:24,  4.36it/s]\n",
      "EP_train | train loss: 0.46887572710290715 | val loss: 0.4356009165445964 |\n",
      "====\n",
      "Epoch:  47%|████▋     | 94/200 [00:21<00:24,  4.40it/s]\n",
      "EP_train | train loss: 0.4651531134295827 | val loss: 0.4325262518490062 |\n",
      "====\n",
      "Epoch:  48%|████▊     | 95/200 [00:21<00:23,  4.43it/s]\n",
      "EP_train | train loss: 0.46289122026730206 | val loss: 0.4302667542999866 |\n",
      "====\n",
      "Epoch:  48%|████▊     | 96/200 [00:22<00:24,  4.32it/s]\n",
      "EP_train | train loss: 0.46352488282978666 | val loss: 0.4310447374979655 |\n",
      "====\n",
      "Epoch:  48%|████▊     | 97/200 [00:22<00:23,  4.35it/s]\n",
      "EP_train | train loss: 0.4624839815958393 | val loss: 0.42417014813890647 |\n",
      "====\n",
      "Epoch:  49%|████▉     | 98/200 [00:22<00:23,  4.39it/s]\n",
      "EP_train | train loss: 0.4584949894408515 | val loss: 0.4266499351052677 |\n",
      "====\n",
      "Epoch:  50%|████▉     | 99/200 [00:22<00:23,  4.39it/s]\n",
      "EP_train | train loss: 0.4581559602990909 | val loss: 0.4236234590119007 |\n",
      "====\n",
      "Epoch:  50%|█████     | 100/200 [00:22<00:22,  4.37it/s]\n",
      "EP_train | train loss: 0.4570881525675456 | val loss: 0.4181530522365196 |\n",
      "====\n",
      "Epoch:  50%|█████     | 101/200 [00:23<00:23,  4.29it/s]\n",
      "EP_train | train loss: 0.4533316045025595 | val loss: 0.4210587856816311 |\n",
      "====\n",
      "Epoch:  51%|█████     | 102/200 [00:23<00:22,  4.34it/s]\n",
      "EP_train | train loss: 0.4534470427270029 | val loss: 0.41897304385316136 |\n",
      "====\n",
      "Epoch:  52%|█████▏    | 103/200 [00:23<00:22,  4.37it/s]\n",
      "EP_train | train loss: 0.45148634131437815 | val loss: 0.416720941954968 |\n",
      "====\n",
      "Epoch:  52%|█████▏    | 104/200 [00:23<00:21,  4.40it/s]\n",
      "EP_train | train loss: 0.45129067082290814 | val loss: 0.4172808890249215 |\n",
      "====\n",
      "Epoch:  52%|█████▎    | 105/200 [00:24<00:21,  4.37it/s]\n",
      "EP_train | train loss: 0.45044246686050315 | val loss: 0.41202452603508444 |\n",
      "====\n",
      "Epoch:  53%|█████▎    | 106/200 [00:24<00:21,  4.29it/s]\n",
      "EP_train | train loss: 0.4467222654222143 | val loss: 0.4127323487225701 |\n",
      "====\n",
      "Epoch:  54%|█████▎    | 107/200 [00:24<00:21,  4.29it/s]\n",
      "EP_train | train loss: 0.4476393136583382 | val loss: 0.41262075012805416 |\n",
      "====\n",
      "Epoch:  54%|█████▍    | 108/200 [00:24<00:21,  4.34it/s]\n",
      "EP_train | train loss: 0.4431542820400662 | val loss: 0.4088150099212048 |\n",
      "====\n",
      "Epoch:  55%|█████▍    | 109/200 [00:24<00:20,  4.34it/s]\n",
      "EP_train | train loss: 0.4444971417030218 | val loss: 0.4052414613611558 |\n",
      "====\n",
      "Epoch:  55%|█████▌    | 110/200 [00:25<00:20,  4.38it/s]\n",
      "EP_train | train loss: 0.44203676896936756 | val loss: 0.4089188856237075 |\n",
      "====\n",
      "Epoch:  56%|█████▌    | 111/200 [00:25<00:20,  4.28it/s]\n",
      "EP_train | train loss: 0.4413145372810447 | val loss: 0.40486923853556317 |\n",
      "====\n",
      "Epoch:  56%|█████▌    | 112/200 [00:25<00:20,  4.32it/s]\n",
      "EP_train | train loss: 0.43846065338400714 | val loss: 0.404087646334779 |\n",
      "====\n",
      "Epoch:  56%|█████▋    | 113/200 [00:25<00:19,  4.36it/s]\n",
      "EP_train | train loss: 0.43842867724516293 | val loss: 0.4012916976330327 |\n",
      "====\n",
      "Epoch:  57%|█████▋    | 114/200 [00:26<00:19,  4.35it/s]\n",
      "EP_train | train loss: 0.4358929683959562 | val loss: 0.40098076240689146 |\n",
      "====\n",
      "Epoch:  57%|█████▊    | 115/200 [00:26<00:19,  4.39it/s]\n",
      "EP_train | train loss: 0.4363371074069819 | val loss: 0.40157662185968135 |\n",
      "====\n",
      "Epoch:  58%|█████▊    | 116/200 [00:26<00:19,  4.21it/s]\n",
      "EP_train | train loss: 0.43465729944067066 | val loss: 0.39643016515993607 |\n",
      "====\n",
      "Epoch:  58%|█████▊    | 117/200 [00:26<00:19,  4.27it/s]\n",
      "EP_train | train loss: 0.4323526291026529 | val loss: 0.4014810300340839 |\n",
      "====\n",
      "Epoch:  59%|█████▉    | 118/200 [00:27<00:19,  4.25it/s]\n",
      "EP_train | train loss: 0.4332782837819949 | val loss: 0.392396141501034 |\n",
      "====\n",
      "Epoch:  60%|█████▉    | 119/200 [00:27<00:18,  4.30it/s]\n",
      "EP_train | train loss: 0.4318031454397962 | val loss: 0.40047402475394456 |\n",
      "====\n",
      "Epoch:  60%|██████    | 120/200 [00:27<00:18,  4.36it/s]\n",
      "EP_train | train loss: 0.4286984971405894 | val loss: 0.3947320077933517 |\n",
      "====\n",
      "Epoch:  60%|██████    | 121/200 [00:27<00:18,  4.28it/s]\n",
      "EP_train | train loss: 0.42721038602276307 | val loss: 0.39424875670788334 |\n",
      "====\n",
      "Epoch:  61%|██████    | 122/200 [00:28<00:18,  4.33it/s]\n",
      "EP_train | train loss: 0.4271807078442542 | val loss: 0.39578018936456416 |\n",
      "====\n",
      "Epoch:  62%|██████▏   | 123/200 [00:28<00:17,  4.35it/s]\n",
      "EP_train | train loss: 0.42641912722120096 | val loss: 0.39026526843800263 |\n",
      "====\n",
      "Epoch:  62%|██████▏   | 124/200 [00:28<00:17,  4.39it/s]\n",
      "EP_train | train loss: 0.42437024002241414 | val loss: 0.3944859598197189 |\n",
      "====\n",
      "Epoch:  62%|██████▎   | 125/200 [00:28<00:17,  4.34it/s]\n",
      "EP_train | train loss: 0.42256970291303914 | val loss: 0.39117297939225737 |\n",
      "====\n",
      "Epoch:  63%|██████▎   | 126/200 [00:28<00:17,  4.23it/s]\n",
      "EP_train | train loss: 0.4241937915743826 | val loss: 0.3901811207042021 |\n",
      "====\n",
      "Epoch:  64%|██████▎   | 127/200 [00:29<00:17,  4.27it/s]\n",
      "EP_train | train loss: 0.42201556515330063 | val loss: 0.3889631570554247 |\n",
      "====\n",
      "Epoch:  64%|██████▍   | 128/200 [00:29<00:16,  4.34it/s]\n",
      "EP_train | train loss: 0.42003693507907175 | val loss: 0.3904886806712431 |\n",
      "====\n",
      "Epoch:  64%|██████▍   | 129/200 [00:29<00:16,  4.37it/s]\n",
      "EP_train | train loss: 0.4201877704113397 | val loss: 0.3913634805118336 |\n",
      "====\n",
      "Epoch:  65%|██████▌   | 130/200 [00:29<00:15,  4.40it/s]\n",
      "EP_train | train loss: 0.4181734829946281 | val loss: 0.38523006439208984 |\n",
      "====\n",
      "Epoch:  66%|██████▌   | 131/200 [00:30<00:15,  4.32it/s]\n",
      "EP_train | train loss: 0.4177228308451202 | val loss: 0.38677606395646635 |\n",
      "====\n",
      "Epoch:  66%|██████▌   | 132/200 [00:30<00:15,  4.32it/s]\n",
      "EP_train | train loss: 0.4158328852102907 | val loss: 0.38707807952282475 |\n",
      "====\n",
      "Epoch:  66%|██████▋   | 133/200 [00:30<00:15,  4.35it/s]\n",
      "EP_train | train loss: 0.4136763990314957 | val loss: 0.3843507953718597 |\n",
      "====\n",
      "Epoch:  67%|██████▋   | 134/200 [00:30<00:15,  4.38it/s]\n",
      "EP_train | train loss: 0.4126704658558166 | val loss: 0.38451451881259097 |\n",
      "====\n",
      "Epoch:  68%|██████▊   | 135/200 [00:31<00:14,  4.35it/s]\n",
      "EP_train | train loss: 0.41202561528074977 | val loss: 0.3821951080771053 |\n",
      "====\n",
      "Epoch:  68%|██████▊   | 136/200 [00:31<00:14,  4.27it/s]\n",
      "EP_train | train loss: 0.4119418108904803 | val loss: 0.3829826841167375 |\n",
      "====\n",
      "Epoch:  68%|██████▊   | 137/200 [00:31<00:14,  4.31it/s]\n",
      "EP_train | train loss: 0.4097715099392893 | val loss: 0.38277119281245214 |\n",
      "====\n",
      "Epoch:  69%|██████▉   | 138/200 [00:31<00:14,  4.35it/s]\n",
      "EP_train | train loss: 0.40822801610743037 | val loss: 0.37914100347780716 |\n",
      "====\n",
      "Epoch:  70%|██████▉   | 139/200 [00:31<00:13,  4.40it/s]\n",
      "EP_train | train loss: 0.4076325503829258 | val loss: 0.3853972846386479 |\n",
      "====\n",
      "Epoch:  70%|███████   | 140/200 [00:32<00:13,  4.43it/s]\n",
      "EP_train | train loss: 0.40585961476909826 | val loss: 0.3816126187642415 |\n",
      "====\n",
      "Epoch:  70%|███████   | 141/200 [00:32<00:13,  4.35it/s]\n",
      "EP_train | train loss: 0.4053198174453769 | val loss: 0.37798328025668276 |\n",
      "====\n",
      "Epoch:  71%|███████   | 142/200 [00:32<00:13,  4.35it/s]\n",
      "EP_train | train loss: 0.4044757211390144 | val loss: 0.3817915635950425 |\n",
      "====\n",
      "Epoch:  72%|███████▏  | 143/200 [00:32<00:13,  4.35it/s]\n",
      "EP_train | train loss: 0.40264821312266497 | val loss: 0.3805837257235658 |\n",
      "====\n",
      "Epoch:  72%|███████▏  | 144/200 [00:33<00:12,  4.32it/s]\n",
      "EP_train | train loss: 0.40133909098722836 | val loss: 0.37943178064682903 |\n",
      "====\n",
      "Epoch:  72%|███████▎  | 145/200 [00:33<00:12,  4.32it/s]\n",
      "EP_train | train loss: 0.4024517691992467 | val loss: 0.3751817217060164 |\n",
      "====\n",
      "Epoch:  73%|███████▎  | 146/200 [00:33<00:12,  4.22it/s]\n",
      "EP_train | train loss: 0.399760204722419 | val loss: 0.37650159761017443 |\n",
      "====\n",
      "Epoch:  74%|███████▎  | 147/200 [00:33<00:12,  4.26it/s]\n",
      "EP_train | train loss: 0.39766364523528186 | val loss: 0.37798692665848077 |\n",
      "====\n",
      "Epoch:  74%|███████▍  | 148/200 [00:34<00:12,  4.28it/s]\n",
      "EP_train | train loss: 0.3971832603670673 | val loss: 0.37503756728826787 |\n",
      "====\n",
      "Epoch:  74%|███████▍  | 149/200 [00:34<00:11,  4.31it/s]\n",
      "EP_train | train loss: 0.3967697885301378 | val loss: 0.37477908414952893 |\n",
      "====\n",
      "Epoch:  75%|███████▌  | 150/200 [00:34<00:11,  4.33it/s]\n",
      "EP_train | train loss: 0.3940231020933662 | val loss: 0.3739520241232479 |\n",
      "====\n",
      "Epoch:  76%|███████▌  | 151/200 [00:34<00:11,  4.24it/s]\n",
      "EP_train | train loss: 0.3929104732272412 | val loss: 0.37620820251165654 |\n",
      "====\n",
      "Epoch:  76%|███████▌  | 152/200 [00:34<00:11,  4.27it/s]\n",
      "EP_train | train loss: 0.39256332330973837 | val loss: 0.3756754819084616 |\n",
      "====\n",
      "Epoch:  76%|███████▋  | 153/200 [00:35<00:10,  4.32it/s]\n",
      "EP_train | train loss: 0.3912167819237138 | val loss: 0.3739061729580748 |\n",
      "====\n",
      "Epoch:  77%|███████▋  | 154/200 [00:35<00:10,  4.37it/s]\n",
      "EP_train | train loss: 0.389999676374049 | val loss: 0.37451231713388483 |\n",
      "====\n",
      "Epoch:  78%|███████▊  | 155/200 [00:35<00:10,  4.40it/s]\n",
      "EP_train | train loss: 0.38955762287630236 | val loss: 0.3702110028734394 |\n",
      "====\n",
      "Epoch:  78%|███████▊  | 156/200 [00:35<00:10,  4.35it/s]\n",
      "EP_train | train loss: 0.3885331517470948 | val loss: 0.3762235641479492 |\n",
      "====\n",
      "Epoch:  78%|███████▊  | 157/200 [00:36<00:09,  4.35it/s]\n",
      "EP_train | train loss: 0.3877596304567291 | val loss: 0.3750186059989181 |\n",
      "====\n",
      "Epoch:  79%|███████▉  | 158/200 [00:36<00:09,  4.40it/s]\n",
      "EP_train | train loss: 0.38560455349276007 | val loss: 0.37070386550005746 |\n",
      "====\n",
      "Epoch:  80%|███████▉  | 159/200 [00:36<00:09,  4.39it/s]\n",
      "EP_train | train loss: 0.38547569058819275 | val loss: 0.3757823308308919 |\n",
      "====\n",
      "Epoch:  80%|████████  | 160/200 [00:36<00:09,  4.31it/s]\n",
      "EP_train | train loss: 0.3834843697890737 | val loss: 0.3718393363204657 |\n",
      "====\n",
      "Epoch:  80%|████████  | 161/200 [00:37<00:09,  4.24it/s]\n",
      "EP_train | train loss: 0.3815153741109345 | val loss: 0.3723534789739871 |\n",
      "====\n",
      "Epoch:  81%|████████  | 162/200 [00:37<00:08,  4.31it/s]\n",
      "EP_train | train loss: 0.3802095799664267 | val loss: 0.3730047169853659 |\n",
      "====\n",
      "Epoch:  82%|████████▏ | 163/200 [00:37<00:08,  4.38it/s]\n",
      "EP_train | train loss: 0.3812261957488548 | val loss: 0.37154196757896274 |\n",
      "====\n",
      "Epoch:  82%|████████▏ | 164/200 [00:37<00:08,  4.32it/s]\n",
      "EP_train | train loss: 0.37789707350055635 | val loss: 0.3697001606810327 |\n",
      "====\n",
      "Epoch:  82%|████████▎ | 165/200 [00:37<00:08,  4.36it/s]\n",
      "EP_train | train loss: 0.37683060382186456 | val loss: 0.37357420079848347 |\n",
      "====\n",
      "Epoch:  83%|████████▎ | 166/200 [00:38<00:07,  4.40it/s]\n",
      "EP_train | train loss: 0.37541432162515476 | val loss: 0.37061596851722867 |\n",
      "====\n",
      "Epoch:  84%|████████▎ | 167/200 [00:38<00:07,  4.43it/s]\n",
      "EP_train | train loss: 0.3751030046176287 | val loss: 0.37104395324108647 |\n",
      "====\n",
      "Epoch:  84%|████████▍ | 168/200 [00:38<00:07,  4.44it/s]\n",
      "EP_train | train loss: 0.37336294116018126 | val loss: 0.3706693742789474 |\n",
      "====\n",
      "Epoch:  84%|████████▍ | 169/200 [00:38<00:06,  4.44it/s]\n",
      "EP_train | train loss: 0.3722080166303514 | val loss: 0.3727821649289599 |\n",
      "====\n",
      "Epoch:  85%|████████▌ | 170/200 [00:39<00:06,  4.41it/s]\n",
      "EP_train | train loss: 0.3704694683515428 | val loss: 0.368838534635656 |\n",
      "====\n",
      "Epoch:  86%|████████▌ | 171/200 [00:39<00:06,  4.27it/s]\n",
      "EP_train | train loss: 0.3690202532250897 | val loss: 0.37184767629586013 |\n",
      "====\n",
      "Epoch:  86%|████████▌ | 172/200 [00:39<00:06,  4.30it/s]\n",
      "EP_train | train loss: 0.36808691461101856 | val loss: 0.3717813304826325 |\n",
      "====\n",
      "Epoch:  86%|████████▋ | 173/200 [00:39<00:06,  4.29it/s]\n",
      "EP_train | train loss: 0.3667913522076243 | val loss: 0.37240709043016623 |\n",
      "====\n",
      "Epoch:  87%|████████▋ | 174/200 [00:39<00:05,  4.36it/s]\n",
      "EP_train | train loss: 0.36494050306432385 | val loss: 0.371495059892243 |\n",
      "====\n",
      "Epoch:  88%|████████▊ | 175/200 [00:40<00:05,  4.35it/s]\n",
      "EP_train | train loss: 0.3642187731458211 | val loss: 0.3707761858023849 |\n",
      "====\n",
      "Epoch:  88%|████████▊ | 176/200 [00:40<00:05,  4.39it/s]\n",
      "EP_train | train loss: 0.36256666432798296 | val loss: 0.37337327470966414 |\n",
      "====\n",
      "Epoch:  88%|████████▊ | 177/200 [00:40<00:05,  4.40it/s]\n",
      "EP_train | train loss: 0.3616426370242582 | val loss: 0.3702726551130706 |\n",
      "====\n",
      "Epoch:  89%|████████▉ | 178/200 [00:40<00:04,  4.43it/s]\n",
      "EP_train | train loss: 0.360842975915647 | val loss: 0.37137643028708067 |\n",
      "====\n",
      "Epoch:  90%|████████▉ | 179/200 [00:41<00:04,  4.46it/s]\n",
      "EP_train | train loss: 0.3591773068463361 | val loss: 0.37399782853968006 |\n",
      "====\n",
      "Epoch:  90%|█████████ | 180/200 [00:41<00:04,  4.46it/s]\n",
      "EP_train | train loss: 0.3575391977181362 | val loss: 0.3694329168282303 |\n",
      "====\n",
      "Epoch:  90%|█████████ | 181/200 [00:41<00:04,  4.36it/s]\n",
      "EP_train | train loss: 0.3556849826654837 | val loss: 0.3720519308950387 |\n",
      "====\n",
      "Epoch:  91%|█████████ | 182/200 [00:41<00:04,  4.39it/s]\n",
      "EP_train | train loss: 0.35486663660452517 | val loss: 0.369776632271561 |\n",
      "====\n",
      "Epoch:  92%|█████████▏| 183/200 [00:42<00:03,  4.42it/s]\n",
      "EP_train | train loss: 0.3537186412769725 | val loss: 0.37194053799498317 |\n",
      "====\n",
      "Epoch:  92%|█████████▏| 184/200 [00:42<00:03,  4.46it/s]\n",
      "EP_train | train loss: 0.3520905114466848 | val loss: 0.3743654138901654 |\n",
      "====\n",
      "Epoch:  92%|█████████▎| 185/200 [00:42<00:03,  4.44it/s]\n",
      "EP_train | train loss: 0.35068577203355844 | val loss: 0.3693853079103956 |\n",
      "====\n",
      "Epoch:  93%|█████████▎| 186/200 [00:42<00:03,  4.44it/s]\n",
      "EP_train | train loss: 0.3495438737806931 | val loss: 0.37407438427794215 |\n",
      "====\n",
      "Epoch:  94%|█████████▎| 187/200 [00:42<00:02,  4.44it/s]\n",
      "EP_train | train loss: 0.34749346257294966 | val loss: 0.3709300452587651 |\n",
      "====\n",
      "Epoch:  94%|█████████▍| 188/200 [00:43<00:02,  4.47it/s]\n",
      "EP_train | train loss: 0.3456845745801406 | val loss: 0.3724565879971373 |\n",
      "====\n",
      "Epoch:  94%|█████████▍| 189/200 [00:43<00:02,  4.47it/s]\n",
      "EP_train | train loss: 0.34472884695514355 | val loss: 0.37288085152121153 |\n",
      "====\n",
      "Epoch:  95%|█████████▌| 190/200 [00:43<00:02,  4.49it/s]\n",
      "EP_train | train loss: 0.3423819136775397 | val loss: 0.37179049323586855 |\n",
      "====\n",
      "Epoch:  96%|█████████▌| 191/200 [00:43<00:02,  4.39it/s]\n",
      "EP_train | train loss: 0.341948668162028 | val loss: 0.37441295735976277 |\n",
      "====\n",
      "Epoch:  96%|█████████▌| 192/200 [00:44<00:01,  4.34it/s]\n",
      "EP_train | train loss: 0.33976238485514987 | val loss: 0.3738252976361443 |\n",
      "====\n",
      "Epoch:  96%|█████████▋| 193/200 [00:44<00:01,  4.34it/s]\n",
      "EP_train | train loss: 0.33858346211884277 | val loss: 0.37381965038823145 |\n",
      "====\n",
      "Epoch:  97%|█████████▋| 194/200 [00:44<00:01,  4.37it/s]\n",
      "EP_train | train loss: 0.33734799366371304 | val loss: 0.37191445219750496 |\n",
      "====\n",
      "Epoch:  98%|█████████▊| 195/200 [00:44<00:01,  4.41it/s]\n",
      "EP_train | train loss: 0.33448690942170056 | val loss: 0.37415196848850624 |\n",
      "====\n",
      "Epoch:  98%|█████████▊| 196/200 [00:44<00:00,  4.42it/s]\n",
      "EP_train | train loss: 0.33282395125993713 | val loss: 0.37477655036776675 |\n",
      "====\n",
      "Epoch:  98%|█████████▊| 197/200 [00:45<00:00,  4.40it/s]\n",
      "EP_train | train loss: 0.33144301163085405 | val loss: 0.3733078919205011 |\n",
      "====\n",
      "Epoch:  99%|█████████▉| 198/200 [00:45<00:00,  4.36it/s]\n",
      "EP_train | train loss: 0.3291034033615345 | val loss: 0.3741871796402277 |\n",
      "====\n",
      "Epoch: 100%|█████████▉| 199/200 [00:45<00:00,  4.39it/s]\n",
      "EP_train | train loss: 0.32781571552384653 | val loss: 0.3722332786111271 |\n",
      "====\n",
      "Epoch: 100%|██████████| 200/200 [00:45<00:00,  4.36it/s]\n",
      "EP_train | train loss: 0.32670631180142007 | val loss: 0.37675126393636066 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(11857, 300, padding_idx=1)\n",
       "  )\n",
       "  (bigramcnn): Sequential(\n",
       "    (0): Conv1d(300, 200, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(200, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (trigramcnn): Sequential(\n",
       "    (0): Conv1d(300, 200, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(200, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (encoder_bigram): LSTM(100, 30, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (encoder_trigram): LSTM(100, 30, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=120, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from attractivenet import AttractiveNet\n",
    "PATH = './model/CNN_LSTM_20201102-213702_0.4347.115'\n",
    "# load_model = TransformerModel(config).to(AttractiveData.device)\n",
    "load_model = AttractiveNet(config).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category, phase):\n",
    "    # if len(sentence) < config['max_seq']:\n",
    "    #     sentence += ['0'] * (config['max_seq'] - len(sentence))\n",
    "    # else:\n",
    "    #     sentence = sentence[:config['max_seq']]\n",
    "\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(0)\n",
    "    # print(tensor_sentence.shape)\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category, phase=phase)\n",
    "\n",
    "    # after_decimal = prediction % 1\n",
    "    # possible_list = [0.0, 0.3333333333333333, 0.6666666666666665, 0.5, 1.0]\n",
    "    # closet_idx = None\n",
    "    # closet_distance = 1\n",
    "    # for i in range(len(possible_list)):\n",
    "    #     if abs(after_decimal - possible_list[i]) <= closet_distance:\n",
    "    #         closet_idx = i\n",
    "    #         closet_distance = abs(after_decimal - possible_list[i])\n",
    "    # prediction = (prediction // 1) + possible_list[closet_idx]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train mean = 3.15, test mean = 2.8\n",
    "predict_list = []\n",
    "with torch.no_grad():\n",
    "    for i, sentence in enumerate(AttractiveData.test_data):\n",
    "        prediction = predict_attractive(sentence.Headline, sentence.Category, 'test')\n",
    "        predict_list.append(prediction.item())\n",
    "        # predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv(config['save_name'] + '.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Below for statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train mean = 3.15, test mean = 2.8\n",
    "# train_list = []\n",
    "# for i, sentence in enumerate(AttractiveData.train_data):\n",
    "#     prediction = predict_attractive(sentence.Headline, sentence.Category, 'train')\n",
    "#     train_list.append(prediction.item())\n",
    "#     # train_list.append(prediction.item())\n",
    "# # print(train_list)\n",
    "# mean_squared_error(pd.read_csv('data/train.csv').sort_values(['ID']).Label.to_list(), train_list), statistics.mean(train_list), statistics.stdev(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list[0:5], pd.read_csv('data/train.csv').sort_values(['ID']).Label.to_list()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = AttractiveData.df_train['Label'].to_list()\n",
    "# statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.6615269709263605, 0.23007971998807042)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.025117757749784954, 2.749250414087909, 0.21818948511921435)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "baseline_list = pd.read_csv('baseline.csv').sort_values(['ID']).Label.to_list()\n",
    "mean_squared_error(baseline_list, predict_list), statistics.mean(baseline_list), statistics.stdev(baseline_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.8167915543795683, 0.14611407210842048)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# LSTM my best\n",
    "# statistics.mean(predict_list), statistics.stdev(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.038789339035529356, 2.8010625587160893, 0.24649253835767065)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "a = pd.read_csv('CNN_LSTM_test.csv').Label.to_list()\n",
    "mean_squared_error(baseline_list, a), statistics.mean(a), statistics.stdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "AttractiveData.TEXT.vocab.itos[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'4.0': 226,\n",
       "         '2.333333333333333': 194,\n",
       "         '4.5': 43,\n",
       "         '3.333333333333333': 313,\n",
       "         '3.6666666666666665': 260,\n",
       "         '2.6666666666666665': 281,\n",
       "         '2.0': 135,\n",
       "         '2.5': 36,\n",
       "         '1.6666666666666667': 28,\n",
       "         '3.0': 354,\n",
       "         '4.333333333333333': 82,\n",
       "         '4.666666666666667': 29,\n",
       "         '1.5': 16,\n",
       "         '3.5': 22,\n",
       "         '1.3333333333333333': 4,\n",
       "         '1.0': 5,\n",
       "         '5.0': 12})"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}