{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "# def tokenizer(corpus):\n",
    "#     return [str(token) for token in nlp(corpus)]\n",
    "# a = '\"River walk that led me to my secret family: after being adopted as a child, Katharine Norbury reveals the emotional journey to reconnect with her biological mother\"'.replace('\"', '')\n",
    "# tokenizer(a)"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_file = './pretrained_embedding/glove.840B.300d.txt'\n",
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "max_size = 128\n",
    "min_freq = 2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'4.0': 226,\n",
       "         '2.3333333333333335': 194,\n",
       "         '4.5': 43,\n",
       "         '3.3333333333333335': 313,\n",
       "         '3.6666666666666665': 260,\n",
       "         '2.6666666666666665': 281,\n",
       "         '2.0': 135,\n",
       "         '2.5': 36,\n",
       "         '1.6666666666666667': 28,\n",
       "         '3.0': 354,\n",
       "         '4.333333333333333': 82,\n",
       "         '4.666666666666667': 29,\n",
       "         '1.5': 16,\n",
       "         '3.5': 22,\n",
       "         '1.3333333333333333': 4,\n",
       "         '1.0': 5,\n",
       "         '5.0': 12})"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.Headline]:[torch.cuda.LongTensor of size 64x64 (GPU 0)]\n",
       "\t[.Label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "batch = next(iter(AttractiveData.trainloader))\n",
    "batch"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4317, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = './model/AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 30\n",
    "lr = 1e-2\n",
    "num_layers = 1\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, AttractiveData.testloader, input_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AttractiveNet(\n",
       "  (embedding): Embedding(4317, 300)\n",
       "  (rnn): RNN(300, 128, num_layers=4, dropout=0.1)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP:0 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 69.02it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 217.26it/s]\n",
      "EP:1 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 88.25it/s]\n",
      "EP_train | avg_loss: 9.68303108215332 |\n",
      "EP:1 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 86.92it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 219.65it/s]\n",
      "EP:2 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 80.77it/s]\n",
      "EP_train | avg_loss: 9.658508211374283 |\n",
      "EP:2 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 84.75it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 219.56it/s]\n",
      "EP:3 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 81.51it/s]\n",
      "EP_train | avg_loss: 9.737947136163712 |\n",
      "EP:3 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 81.17it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 203.67it/s]\n",
      "EP:4 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 83.63it/s]\n",
      "EP_train | avg_loss: 9.681198596954346 |\n",
      "EP:4 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 88.27it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 195.67it/s]\n",
      "EP:5 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 82.02it/s]\n",
      "EP_train | avg_loss: 9.669366478919983 |\n",
      "EP:5 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 77.65it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 215.57it/s]\n",
      "EP:6 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 87.28it/s]\n",
      "EP_train | avg_loss: 9.69224613904953 |\n",
      "EP:6 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 86.48it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 216.76it/s]\n",
      "EP:7 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 85.90it/s]\n",
      "EP_train | avg_loss: 9.683029979467392 |\n",
      "EP:7 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 84.49it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 201.94it/s]\n",
      "EP:8 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 83.20it/s]\n",
      "EP_train | avg_loss: 9.697893753647804 |\n",
      "EP:8 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 85.21it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 214.05it/s]\n",
      "EP:9 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 87.48it/s]\n",
      "EP_train | avg_loss: 9.690000206232071 |\n",
      "EP:9 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 89.64it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 199.35it/s]\n",
      "EP:10 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 81.93it/s]\n",
      "EP_train | avg_loss: 9.658741116523743 |\n",
      "EP:10 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 81.54it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 218.99it/s]\n",
      "EP:11 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 84.39it/s]\n",
      "EP_train | avg_loss: 9.669587776064873 |\n",
      "EP:11 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 88.73it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 192.39it/s]\n",
      "EP:12 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 86.65it/s]\n",
      "EP_train | avg_loss: 9.690164923667908 |\n",
      "EP:12 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 86.55it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 214.68it/s]\n",
      "EP:13 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 81.83it/s]\n",
      "EP_train | avg_loss: 9.801946505904198 |\n",
      "EP:13 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.38it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 218.72it/s]\n",
      "EP:14 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 85.82it/s]\n",
      "EP_train | avg_loss: 9.727790668606758 |\n",
      "EP:14 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.71it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 214.24it/s]\n",
      "EP:15 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 81.49it/s]\n",
      "EP_train | avg_loss: 9.65511828660965 |\n",
      "EP:15 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 87.90it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 219.70it/s]\n",
      "EP:16 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 86.68it/s]\n",
      "EP_train | avg_loss: 9.721743732690811 |\n",
      "EP:16 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 85.49it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 201.68it/s]\n",
      "EP:17 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 80.49it/s]\n",
      "EP_train | avg_loss: 9.69786787033081 |\n",
      "EP:17 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.57it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 215.21it/s]\n",
      "EP:18 | lr: 0.01:  25%|| 8/32 [00:00<00:00, 79.49it/s]\n",
      "EP_train | avg_loss: 9.749932885169983 |\n",
      "EP:18 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 80.17it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 168.67it/s]\n",
      "EP:19 | lr: 0.01:  25%|| 8/32 [00:00<00:00, 77.18it/s]\n",
      "EP_train | avg_loss: 9.652848720550537 |\n",
      "EP:19 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.36it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 188.87it/s]\n",
      "EP:20 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 85.15it/s]\n",
      "EP_train | avg_loss: 9.662110552191734 |\n",
      "EP:20 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 86.98it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 214.71it/s]\n",
      "EP:21 | lr: 0.01:  25%|| 8/32 [00:00<00:00, 75.77it/s]\n",
      "EP_train | avg_loss: 9.706995502114296 |\n",
      "EP:21 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.04it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 193.87it/s]\n",
      "EP:22 | lr: 0.01:  25%|| 8/32 [00:00<00:00, 78.40it/s]\n",
      "EP_train | avg_loss: 9.751872837543488 |\n",
      "EP:22 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.62it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 217.93it/s]\n",
      "EP:23 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 86.80it/s]\n",
      "EP_train | avg_loss: 9.675011843442917 |\n",
      "EP:23 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 87.67it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 219.72it/s]\n",
      "EP:24 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 82.31it/s]\n",
      "EP_train | avg_loss: 9.80566617846489 |\n",
      "EP:24 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 83.86it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 221.02it/s]\n",
      "EP:25 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 85.43it/s]\n",
      "EP_train | avg_loss: 9.686687499284744 |\n",
      "EP:25 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 85.93it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 217.45it/s]\n",
      "EP:26 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 87.55it/s]\n",
      "EP_train | avg_loss: 9.663681477308273 |\n",
      "EP:26 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 87.09it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 220.08it/s]\n",
      "EP:27 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 88.77it/s]\n",
      "EP_train | avg_loss: 9.677151888608932 |\n",
      "EP:27 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 87.33it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 218.40it/s]\n",
      "EP:28 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 87.05it/s]\n",
      "EP_train | avg_loss: 9.676244482398033 |\n",
      "EP:28 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 87.09it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 213.35it/s]\n",
      "EP:29 | lr: 0.01:  28%|| 9/32 [00:00<00:00, 85.13it/s]\n",
      "EP_train | avg_loss: 9.685653924942017 |\n",
      "EP:29 | lr: 0.01: 100%|| 32/32 [00:00<00:00, 87.16it/s]\n",
      "EP: train | lr: 0.01: 100%|| 32/32 [00:00<00:00, 210.75it/s]\n",
      "\n",
      "EP_train | avg_loss: 9.66500099003315 |\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence):\n",
    "    tokens = AttractiveData.tokenizer(sentence)\n",
    "    indexed = [AttractiveData.TEXT.vocab.stoi[t] for t in tokens]\n",
    "    tensor = torch.LongTensor(indexed).to(AttractiveData.device)\n",
    "\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = AttractiveTrainer.model(tensor)\n",
    "    \n",
    "    return prediction[0][0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5558767914772034"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "a = \"Traditional Bombay-style Cafe beats Heston Blumenthal's Michelin-starred restaurant to be crowned the best in the Uk\"\n",
    "prediction = predict_attractive(a)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "EP: test | lr: 0.01:   0%|| 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'Text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2143512279e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttractiveTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_loader, str_code)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHeadline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mattractive_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             self.batches = batch(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    252\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS_hw2/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NCTU_courses/Data-Science-2020-Spring-NCTU/HW2/2-2/attractivedata.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         self.trainloader, self.testloader = data.BucketIterator.splits(\n\u001b[0;32m---> 36\u001b[0;31m             (self.train_data, self.test_data), sort_key=lambda x: len(x.Text), batch_size=batch_size, device=self.device)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# self.padding_train = self.padding(self.df_train.Headline.to_list())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "pred, true = AttractiveTrainer.evaluate(AttractiveTrainer.test_loader, 'test')"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}