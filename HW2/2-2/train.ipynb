{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.42B.300d'\n",
    "max_size = 64\n",
    "min_freq = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.333333333333333'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in range(i):\n",
    "    if len(AttractiveData.test_data[i].Headline) >= max_len:\n",
    "        max_len = len(AttractiveData.test_data[i].Headline)\n",
    "max_len"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1519, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = 'AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "\n",
    "category_dim = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "category_output_dim = 16\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 200\n",
    "lr = {\n",
    "    'transformer_encoder': 1e-5,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-4\n",
    "}\n",
    "num_layers = 4\n",
    "nhead = 4\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers, nhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1519, 300, padding_idx=1)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100%|| 32/32 [00:00<00:00, 106.43it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5446687769144773 |\n",
      "Epoch 888\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 102.56it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5450941622257233 |\n",
      "Epoch 889\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5448642922565341 |\n",
      "Epoch 890\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.39it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5446487432345748 |\n",
      "Epoch 891\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 103.80it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5471216924488544 |\n",
      "Epoch 892\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 102.81it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5460886945948005 |\n",
      "Epoch 893\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 102.90it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5445029260590672 |\n",
      "Epoch 894\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 102.44it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.54249900393188 |\n",
      "Epoch 895\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 103.90it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.544819887727499 |\n",
      "Epoch 896\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 102.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5469044484198093 |\n",
      "Epoch 897\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 105.29it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.544947037473321 |\n",
      "Epoch 898\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 101.70it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442467276006937 |\n",
      "Epoch 899\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 83.19it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5440479833632708 |\n",
      "Epoch 900\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 100.53it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5453811651095748 |\n",
      "Epoch 901\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 97.68it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5447989087551832 |\n",
      "Epoch 902\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 107.00it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5449850643053651 |\n",
      "Epoch 903\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5454211728647351 |\n",
      "Epoch 904\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5430985977873206 |\n",
      "Epoch 905\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 104.87it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5444082673639059 |\n",
      "Epoch 906\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.98it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5436369394883513 |\n",
      "Epoch 907\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 107.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442045535892248 |\n",
      "Epoch 908\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.544910466298461 |\n",
      "Epoch 909\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.95it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5458205351606011 |\n",
      "Epoch 910\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 106.44it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5459556998685002 |\n",
      "Epoch 911\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 112.50it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5449795192107558 |\n",
      "Epoch 912\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.94it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5438265632838011 |\n",
      "Epoch 913\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 109.89it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5444758459925652 |\n",
      "Epoch 914\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.14it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5448057502508163 |\n",
      "Epoch 915\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441082743927836 |\n",
      "Epoch 916\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.59it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441266559064388 |\n",
      "Epoch 917\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 111.57it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5460901195183396 |\n",
      "Epoch 918\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 109.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5450882194563746 |\n",
      "Epoch 919\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.38it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5453333221375942 |\n",
      "Epoch 920\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.38it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5462146010249853 |\n",
      "Epoch 921\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 111.09it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5439769206568599 |\n",
      "Epoch 922\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5433395756408572 |\n",
      "Epoch 923\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.09it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5435568895190954 |\n",
      "Epoch 924\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 108.95it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5449425671249628 |\n",
      "Epoch 925\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 111.43it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5440668566152453 |\n",
      "Epoch 926\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5460432767868042 |\n",
      "Epoch 927\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.82it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5434527695178986 |\n",
      "Epoch 928\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 110.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5428764168173075 |\n",
      "Epoch 929\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.01it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5428216783329844 |\n",
      "Epoch 930\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5452071372419596 |\n",
      "Epoch 931\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5436048954725266 |\n",
      "Epoch 932\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.48it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.54494374897331 |\n",
      "Epoch 933\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5447854297235608 |\n",
      "Epoch 934\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.08it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5440019313246012 |\n",
      "Epoch 935\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.29it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5451383134350181 |\n",
      "Epoch 936\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.88it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5438412129878998 |\n",
      "Epoch 937\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.41it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5445955591276288 |\n",
      "Epoch 938\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.75it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.543248531408608 |\n",
      "Epoch 939\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.47it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442529758438468 |\n",
      "Epoch 940\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.27it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5457818666473031 |\n",
      "Epoch 941\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5454566208645701 |\n",
      "Epoch 942\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 112.91it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.542921113781631 |\n",
      "Epoch 943\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.97it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5448712101206183 |\n",
      "Epoch 944\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.32it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5451355837285519 |\n",
      "Epoch 945\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 110.48it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5448579387739301 |\n",
      "Epoch 946\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441317744553089 |\n",
      "Epoch 947\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 110.59it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5447280192747712 |\n",
      "Epoch 948\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 109.92it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5449627852067351 |\n",
      "Epoch 949\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 111.77it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5451837526634336 |\n",
      "Epoch 950\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.59it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.544202471151948 |\n",
      "Epoch 951\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.16it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5432972265407443 |\n",
      "Epoch 952\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.49it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5436879945918918 |\n",
      "Epoch 953\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 109.44it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5461709080263972 |\n",
      "Epoch 954\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.00it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5446004290133715 |\n",
      "Epoch 955\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.76it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5452143251895905 |\n",
      "Epoch 956\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.14it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5448707025498152 |\n",
      "Epoch 957\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.69it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5450194487348199 |\n",
      "Epoch 958\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 109.55it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5434745019301772 |\n",
      "Epoch 959\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.64it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5446266448125243 |\n",
      "Epoch 960\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 111.58it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5451228311285377 |\n",
      "Epoch 961\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.65it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5462287943810225 |\n",
      "Epoch 962\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.57it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.545296267606318 |\n",
      "Epoch 963\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.88it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.545248500071466 |\n",
      "Epoch 964\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 117.46it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442234873771667 |\n",
      "Epoch 965\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.89it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5443033576011658 |\n",
      "Epoch 966\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.90it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5440548900514841 |\n",
      "Epoch 967\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.33it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.543512474745512 |\n",
      "Epoch 968\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.544072225689888 |\n",
      "Epoch 969\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.22it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5426574386656284 |\n",
      "Epoch 970\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.00it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5448532123118639 |\n",
      "Epoch 971\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.59it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5434846561402082 |\n",
      "Epoch 972\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442669847980142 |\n",
      "Epoch 973\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.27it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442784540355206 |\n",
      "Epoch 974\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.53it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5442336555570364 |\n",
      "Epoch 975\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.20it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5445303646847606 |\n",
      "Epoch 976\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.79it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441404711455107 |\n",
      "Epoch 977\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.40it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5454900125041604 |\n",
      "Epoch 978\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.49it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5445100022479892 |\n",
      "Epoch 979\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.37it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5450352942571044 |\n",
      "Epoch 980\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.41it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5451288744807243 |\n",
      "Epoch 981\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.69it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5449284203350544 |\n",
      "Epoch 982\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.49it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441842470318079 |\n",
      "Epoch 983\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 116.85it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5444863988086581 |\n",
      "Epoch 984\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.02it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441921278834343 |\n",
      "Epoch 985\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.51it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5460275150835514 |\n",
      "Epoch 986\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 112.01it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5429602088406682 |\n",
      "Epoch 987\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 113.99it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5440205344930291 |\n",
      "Epoch 988\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5449986821040511 |\n",
      "Epoch 989\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.42it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5455608749762177 |\n",
      "Epoch 990\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.02it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5466704983264208 |\n",
      "Epoch 991\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.13it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.544997027143836 |\n",
      "Epoch 992\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.97it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5441125780344009 |\n",
      "Epoch 993\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.58it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5433697355911136 |\n",
      "Epoch 994\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5446522096171975 |\n",
      "Epoch 995\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.75it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5438946234062314 |\n",
      "Epoch 996\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.08it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5438491543754935 |\n",
      "Epoch 997\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.77it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5446964232251048 |\n",
      "Epoch 998\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 110.62it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.542587042786181 |\n",
      "Epoch 999\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 114.99it/s]\n",
      "EP_train | avg_loss: 0.5431518461555243 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5601443355119825"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# a = AttractiveTrainer.train_predict\n",
    "# AttractiveData.LABEL.vocab.itos[int(a[0])], AttractiveTrainer.train_true[0]\n",
    "# correct = 0\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "# for i in range(len(a)):\n",
    "#     pred = AttractiveData.LABEL.vocab.itos[int(a[i])]\n",
    "#     pred_list.append(float(pred))\n",
    "#     true = AttractiveData.LABEL.vocab.itos[int(AttractiveTrainer.train_true[i])]\n",
    "#     true_list.append(float(true))\n",
    "# mean_squared_error(true_list, pred_list)\n",
    "# # true_list"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1519, 300, padding_idx=1)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from transformermodel import TransformerModel\n",
    "PATH = './model/AttractiveNet_20201030-104806_0.543.1000'\n",
    "load_model = TransformerModel(nhead, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, dropout, num_layers).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "    tensor_category = tensor_category\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ngolf\nbeauty\n"
     ]
    }
   ],
   "source": [
    "train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "for each_test in test_category:\n",
    "    if each_test not in train_category:\n",
    "        print(each_test)\n",
    "print()\n",
    "for each_train in train_category:\n",
    "    if each_train not in test_category:\n",
    "        print(each_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['travel',\n",
       "  'health',\n",
       "  'femail',\n",
       "  'sport',\n",
       "  'gardening',\n",
       "  'sciencetech',\n",
       "  'news',\n",
       "  'food',\n",
       "  'football',\n",
       "  'travelnews',\n",
       "  'cricket',\n",
       "  'golf',\n",
       "  'books',\n",
       "  'rugbyunion',\n",
       "  'home',\n",
       "  'boxing',\n",
       "  'tennis',\n",
       "  'concussion',\n",
       "  'othersports',\n",
       "  'beauty',\n",
       "  'formulaone',\n",
       "  'racing'],\n",
       " ['health',\n",
       "  'femail',\n",
       "  'sciencetech',\n",
       "  'travel',\n",
       "  'news',\n",
       "  'football',\n",
       "  'food',\n",
       "  'living',\n",
       "  'books',\n",
       "  'boxing',\n",
       "  'rugbyunion',\n",
       "  'othersports',\n",
       "  'formulaone',\n",
       "  'cricket',\n",
       "  'us',\n",
       "  'tennis',\n",
       "  'sport',\n",
       "  'middleeast',\n",
       "  'racing'])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_category, test_category"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}