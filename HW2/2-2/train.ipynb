{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "display_name": "Python 3.6.12 64-bit ('DS_hw2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "de6ec751e8d816810380d8c8f13d270f86a313990c5d5930d253da012ff5e7fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# # DL framework\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "from attractivedata import AttractiveData\n",
    "from trainer import AttractiveTrainer"
   ]
  },
  {
   "source": [
    "## Load and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "pretrained_file = 'glove.42B.300d'\n",
    "max_size = 64\n",
    "min_freq = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData = AttractiveData(train_file, test_file, pretrained_file, max_size, min_freq, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Headline': ['Sorry', ',', 'i', 'spent', 'it', 'on', 'myself', '!', 'Harvey', 'Nichols', \"'\", 'hilarious', 'Christmas', 'advert', 'sees', 'people', 'treating', 'themselves', 'instead', 'of', 'others'], 'Category': 'femail', 'Label': '3.333333333333333'} {'Headline': ['Three', 'police', 'officers', 'accused', 'of', 'stealing', '?', '?', '30k', 'during', 'raid', 'on', 'criminal'], 'Category': 'news'}\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    if i == 3:\n",
    "        print(vars(AttractiveData.train_data[i]), vars(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(AttractiveData.CATEGORIES_LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttractiveData.LABEL.vocab.freqs"
   ]
  },
  {
   "source": [
    "## Start to train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1519, 300])\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_name = 'AttractiveNet'\n",
    "num_workers = 10\n",
    "input_dim = len(AttractiveData.TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "\n",
    "category_dim = len(AttractiveData.CATEGORIES_LABEL.vocab)\n",
    "category_output_dim = 16\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "log_steps = 10\n",
    "epochs = 100\n",
    "lr = {\n",
    "    'transformer_encoder': 1e-5,\n",
    "    'embedding': 1e-5,\n",
    "    'linear': 1e-4\n",
    "}\n",
    "num_layers = 4\n",
    "nhead = 4\n",
    "dropout = 0.1\n",
    "pretrained_embeddings = AttractiveData.TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(AttractiveData.df_train.Headline.str.len()), max(AttractiveData.df_test.Headline.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveTrainer = AttractiveTrainer(save_name, log_steps, epochs, lr, timestr, AttractiveData.device, AttractiveData.trainloader, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, pretrained_embeddings, dropout, num_layers, nhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1519, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "AttractiveTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.65it/s]\n",
      "\n",
      "EP_train | avg_loss: 1.123417291790247 |\n",
      "Epoch 1\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.16it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6650555841624737 |\n",
      "Epoch 2\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.21it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6341596730053425 |\n",
      "Epoch 3\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.77it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6294561102986336 |\n",
      "Epoch 4\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6213726652786136 |\n",
      "Epoch 5\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.69it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6090054428204894 |\n",
      "Epoch 6\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 115.02it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.604508750140667 |\n",
      "Epoch 7\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.23it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.6002265233546495 |\n",
      "Epoch 8\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.68it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5945834973827004 |\n",
      "Epoch 9\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.41it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5919965440407395 |\n",
      "Epoch 10\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.83it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5880958689376712 |\n",
      "Epoch 11\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5876445975154638 |\n",
      "Epoch 12\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.24it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.583646192215383 |\n",
      "Epoch 13\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.62it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5774077167734504 |\n",
      "Epoch 14\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.46it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5755492690950632 |\n",
      "Epoch 15\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.28it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5748326815664768 |\n",
      "Epoch 16\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.23it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5750368405133486 |\n",
      "Epoch 17\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.63it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.573723210953176 |\n",
      "Epoch 18\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.98it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5740902572870255 |\n",
      "Epoch 19\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 122.54it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5736867245286703 |\n",
      "Epoch 20\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.39it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5723919020965695 |\n",
      "Epoch 21\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 117.42it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.573113446123898 |\n",
      "Epoch 22\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.11it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5698042185977101 |\n",
      "Epoch 23\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.80it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5690821334719658 |\n",
      "Epoch 24\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.57it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5667048301547766 |\n",
      "Epoch 25\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.62it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5671635428443551 |\n",
      "Epoch 26\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.38it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5655193999409676 |\n",
      "Epoch 27\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.564307558350265 |\n",
      "Epoch 28\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.55it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5652561215683818 |\n",
      "Epoch 29\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.10it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5631649484857917 |\n",
      "Epoch 30\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5633976683020592 |\n",
      "Epoch 31\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.31it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.562337052077055 |\n",
      "Epoch 32\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 117.71it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5619437545537949 |\n",
      "Epoch 33\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.29it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5635547135025263 |\n",
      "Epoch 34\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.28it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5605839863419533 |\n",
      "Epoch 35\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.46it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5604474190622568 |\n",
      "Epoch 36\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.43it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5599974822252989 |\n",
      "Epoch 37\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.67it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5611426439136267 |\n",
      "Epoch 38\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5611216872930527 |\n",
      "Epoch 39\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5620804158970714 |\n",
      "Epoch 40\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 117.25it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5602423185482621 |\n",
      "Epoch 41\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5582889039069414 |\n",
      "Epoch 42\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.74it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5569969648495317 |\n",
      "Epoch 43\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.61it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5598148331046104 |\n",
      "Epoch 44\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.24it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5585658643394709 |\n",
      "Epoch 45\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.35it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5586547320708632 |\n",
      "Epoch 46\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.21it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5589565057307482 |\n",
      "Epoch 47\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.20it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5570260314270854 |\n",
      "Epoch 48\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.98it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5584503496065736 |\n",
      "Epoch 49\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5582276182249188 |\n",
      "Epoch 50\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.93it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5573000675067306 |\n",
      "Epoch 51\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.36it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5573507165536284 |\n",
      "Epoch 52\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.10it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5561695778742433 |\n",
      "Epoch 53\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5559813641011715 |\n",
      "Epoch 54\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.41it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5585943125188351 |\n",
      "Epoch 55\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.78it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.556792039424181 |\n",
      "Epoch 56\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.72it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5571624021977186 |\n",
      "Epoch 57\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.69it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5548828225582838 |\n",
      "Epoch 58\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.57it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5585486497730017 |\n",
      "Epoch 59\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 117.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.555433502420783 |\n",
      "Epoch 60\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.96it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5560998003929853 |\n",
      "Epoch 61\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.94it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5556084746494889 |\n",
      "Epoch 62\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.34it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5553172286599874 |\n",
      "Epoch 63\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.65it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5559981530532241 |\n",
      "Epoch 64\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.26it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5573234530165792 |\n",
      "Epoch 65\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.75it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5566906556487083 |\n",
      "Epoch 66\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.58it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5561442580074072 |\n",
      "Epoch 67\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.96it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5521946744993329 |\n",
      "Epoch 68\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.55it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5529889957979321 |\n",
      "Epoch 69\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.19it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5535471206530929 |\n",
      "Epoch 70\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.37it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5529253492131829 |\n",
      "Epoch 71\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.03it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5526748150587082 |\n",
      "Epoch 72\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.88it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5542180677875876 |\n",
      "Epoch 73\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.99it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5546488156542182 |\n",
      "Epoch 74\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.98it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5530094709247351 |\n",
      "Epoch 75\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.24it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5540729835629463 |\n",
      "Epoch 76\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.95it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5534520745277405 |\n",
      "Epoch 77\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.56it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.554850846529007 |\n",
      "Epoch 78\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.96it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5546077582985163 |\n",
      "Epoch 79\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.93it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5528972884640098 |\n",
      "Epoch 80\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.99it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5534103512763977 |\n",
      "Epoch 81\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.18it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.552300626412034 |\n",
      "Epoch 82\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.64it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5520938215777278 |\n",
      "Epoch 83\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.22it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5528164384886622 |\n",
      "Epoch 84\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5524626513943076 |\n",
      "Epoch 85\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 121.17it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5506122307851911 |\n",
      "Epoch 86\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5511666461825371 |\n",
      "Epoch 87\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.07it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5517763672396541 |\n",
      "Epoch 88\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.04it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5527795506641269 |\n",
      "Epoch 89\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.60it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.549840827472508 |\n",
      "Epoch 90\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.52it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5510483477264643 |\n",
      "Epoch 91\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5521473037078977 |\n",
      "Epoch 92\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.49it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.550994923338294 |\n",
      "Epoch 93\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.84it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5546751515939832 |\n",
      "Epoch 94\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.86it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.552007369697094 |\n",
      "Epoch 95\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 118.43it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5518886912614107 |\n",
      "Epoch 96\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.34it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5532252807170153 |\n",
      "Epoch 97\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 119.81it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5507366312667727 |\n",
      "Epoch 98\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.57it/s]\n",
      "\n",
      "EP_train | avg_loss: 0.5529233179986477 |\n",
      "Epoch 99\n",
      "EP: train | lr: {'transformer_encoder': 1e-05, 'embedding': 1e-05, 'linear': 0.0001}: 100%|| 32/32 [00:00<00:00, 120.28it/s]\n",
      "EP_train | avg_loss: 0.5521437078714371 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttractiveTrainer.train()"
   ]
  },
  {
   "source": [
    "## for classification, not better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5601443355119825"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# a = AttractiveTrainer.train_predict\n",
    "# AttractiveData.LABEL.vocab.itos[int(a[0])], AttractiveTrainer.train_true[0]\n",
    "# correct = 0\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "# for i in range(len(a)):\n",
    "#     pred = AttractiveData.LABEL.vocab.itos[int(a[i])]\n",
    "#     pred_list.append(float(pred))\n",
    "#     true = AttractiveData.LABEL.vocab.itos[int(AttractiveTrainer.train_true[i])]\n",
    "#     true_list.append(float(true))\n",
    "# mean_squared_error(true_list, pred_list)\n",
    "# # true_list"
   ]
  },
  {
   "source": [
    "## Below is testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): AttractiveEmbedding(\n",
       "    (token): TokenEmbedding(1519, 300, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (category_embedding): CategoryEmbedding(18, 16, padding_idx=0)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=316, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from transformermodel import TransformerModel\n",
    "PATH = './model/AttractiveNet_20201029-163658_0.552.100'\n",
    "load_model = TransformerModel(nhead, input_dim, category_dim, category_output_dim, embedding_dim, hidden_dim, output_dim, dropout, num_layers).to(AttractiveData.device)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attractive(sentence, category):\n",
    "    indexed_sentence = [AttractiveData.TEXT.vocab.stoi[t] for t in sentence]\n",
    "    indexed_category = [AttractiveData.CATEGORIES_LABEL.vocab.stoi[category]]\n",
    "    tensor_sentence = torch.LongTensor(indexed_sentence).to(AttractiveData.device)\n",
    "    tensor_category = torch.LongTensor(indexed_category).to(AttractiveData.device)\n",
    "\n",
    "    tensor_sentence = tensor_sentence.unsqueeze(1)\n",
    "    tensor_category = tensor_category\n",
    "\n",
    "    prediction = load_model(tensor_sentence, tensor_category)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "for i, sentence in enumerate(AttractiveData.test_data):\n",
    "    prediction = predict_attractive(sentence.Headline, sentence.Category)\n",
    "    predict_list.append(prediction.item())\n",
    "AttractiveData.df_test['Label'] = predict_list\n",
    "AttractiveData.df_test[['ID', 'Label']].to_csv('transformers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ngolf\nbeauty\n"
     ]
    }
   ],
   "source": [
    "train_category = list(AttractiveData.CATEGORIES_LABEL.vocab.freqs)\n",
    "test_category = list(AttractiveData.df_test['Category'].value_counts().keys())\n",
    "for each_test in test_category:\n",
    "    if each_test not in train_category:\n",
    "        print(each_test)\n",
    "print()\n",
    "for each_train in train_category:\n",
    "    if each_train not in test_category:\n",
    "        print(each_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['travel',\n",
       "  'health',\n",
       "  'femail',\n",
       "  'sport',\n",
       "  'gardening',\n",
       "  'sciencetech',\n",
       "  'news',\n",
       "  'food',\n",
       "  'football',\n",
       "  'travelnews',\n",
       "  'cricket',\n",
       "  'golf',\n",
       "  'books',\n",
       "  'rugbyunion',\n",
       "  'home',\n",
       "  'boxing',\n",
       "  'tennis',\n",
       "  'concussion',\n",
       "  'othersports',\n",
       "  'beauty',\n",
       "  'formulaone',\n",
       "  'racing'],\n",
       " ['health',\n",
       "  'femail',\n",
       "  'sciencetech',\n",
       "  'travel',\n",
       "  'news',\n",
       "  'football',\n",
       "  'food',\n",
       "  'living',\n",
       "  'books',\n",
       "  'boxing',\n",
       "  'rugbyunion',\n",
       "  'othersports',\n",
       "  'formulaone',\n",
       "  'cricket',\n",
       "  'us',\n",
       "  'tennis',\n",
       "  'sport',\n",
       "  'middleeast',\n",
       "  'racing'])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_category, test_category"
   ]
  },
  {
   "source": [
    "## Below just for fun guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AttractiveData.df_test['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5545343137254902"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mean_squared_error(a, b)\n",
    "# Training all 3.0 got mse = 0.5545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for fun\n",
    "import random\n",
    "guess_list = [2.3333333333333335, 3.3333333333333335, 3.6666666666666665, 2.6666666666666665]\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(random.choice(guess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test['Label'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttractiveData.df_test[['ID', 'Label']].to_csv('all_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}